{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import seaborn as sns\n",
    "import random\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "from scipy import stats\n",
    "import copy\n",
    "import glob\n",
    "import os\n",
    "import pickle\n",
    "from invoke import run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Global Attention Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 1., 2., 3.],\n",
      "        [1., 0., 1., 2.],\n",
      "        [2., 1., 0., 1.],\n",
      "        [3., 2., 1., 0.]], dtype=torch.float64)\n",
      "tensor([[ 0.,  1.,  2.,  3.],\n",
      "        [-1.,  0.,  1.,  2.],\n",
      "        [-2., -1.,  0.,  1.],\n",
      "        [-3., -2., -1.,  0.]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "def flatten(t):\n",
    "    return [item for sublist in t for item in sublist]\n",
    "\n",
    "def get_positions_distances_mat(length, negative=False):\n",
    "    '''\n",
    "    For length 4:\n",
    "    distance matrix = [[1,2,3,4],[2,1,2,3],[3,2,1,2],[4,3,2,1]]\n",
    "    '''\n",
    "    \n",
    "    distances_matrix = np.zeros((length,length))\n",
    "    tri = flatten([list(np.arange(i)+1) for i in range(length-1,0,-1)])\n",
    "    distances_matrix[np.triu_indices(length,1)] = tri\n",
    "    if not negative:\n",
    "        distances_matrix += distances_matrix.T\n",
    "    else:\n",
    "        distances_matrix -= distances_matrix.T\n",
    "    \n",
    "    if not negative: \n",
    "        return torch.tensor(distances_matrix)# + 1\n",
    "    else:\n",
    "        return torch.tensor(distances_matrix)\n",
    "    \n",
    "print(get_positions_distances_mat(4))\n",
    "print(get_positions_distances_mat(4,True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_global_metric(attn_mat):\n",
    "    '''\n",
    "    Calculate a metric to estimate how much a given attntion head is global in thier weights.\n",
    "    For a given head, the calculation is a mean weighted sum for every token.\n",
    "    The score for token in position i = sum_{for every token in position j}(a/num_of_tokens)\n",
    "    \n",
    "    A score of 1.0 is completely global, a score of 1/num_of_tokens is completely local.\n",
    "    '''\n",
    "    \n",
    "    cur_max_position = attn_mat.shape[-1] # maximal number of tokens\n",
    "    distances_matrix = get_positions_distances_mat(cur_max_position).to(attn_mat.device) # global weights, the higher the more global\n",
    "    \n",
    "    # normlize weights to sum to 1.0, in case they don't (in remove EOS)\n",
    "    norm_attn_mat = attn_mat / attn_mat.sum(dim=1).unsqueeze(1).expand(attn_mat.shape)\n",
    "    \n",
    "    sum_mat = torch.sum(distances_matrix*norm_attn_mat,axis=len(norm_attn_mat.shape)-1)\n",
    "    normalized_weight_distanced = sum_mat / (cur_max_position + 1) # normlize score according to length so max is 1\n",
    "    \n",
    "    return normalized_weight_distanced.mean(-1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_median(data, weights):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "      data (list or numpy.array): data\n",
    "      weights (list or numpy.array): weights\n",
    "    \n",
    "    returns the weighted median in data according to weights (float)\n",
    "    \"\"\"\n",
    "    data, weights = np.array(data).squeeze(), np.array(weights).squeeze()\n",
    "    s_data, s_weights = map(np.array, zip(*sorted(zip(data, weights))))\n",
    "    midpoint = 0.5 * sum(s_weights)\n",
    "    if any(weights > midpoint):\n",
    "        w_median = (data[weights == np.max(weights)])[0]\n",
    "    else:\n",
    "        cs_weights = np.cumsum(s_weights)\n",
    "        idx = np.where(cs_weights <= midpoint)[0][-1]\n",
    "        if cs_weights[idx] == midpoint:\n",
    "            w_median = np.mean(s_data[idx:idx+2])\n",
    "        else:\n",
    "            w_median = s_data[idx+1]\n",
    "    return w_median\n",
    "    \n",
    "def get_mean_distance_weighted_median(attn_mat):\n",
    "    num_of_tokens = attn_mat.shape[0]\n",
    "    dists = get_positions_distances_mat(num_of_tokens,negative=True)\n",
    "    #sum_of_weighted_medians = 0\n",
    "    all_weighted_medians = []\n",
    "    for index_token in range(num_of_tokens):\n",
    "        cur_weighted_median = weighted_median(dists[index_token], attn_mat[index_token]/sum(attn_mat[index_token])) # scale weights to sum to 1.0 if they are not (in remove EOS)\n",
    "        # sum_of_weighted_medians += abs(cur_weighted_median)\n",
    "        all_weighted_medians.append(abs(cur_weighted_median))\n",
    "    return np.percentile(all_weighted_medians, 90)\n",
    "\n",
    "def get_model_wmd_gloablity_scores(attn_mat, LENGTH, with_eos=True):\n",
    "    distance_weighted_median = []\n",
    "    globality_scores = []\n",
    "    for i in range(NUM_LAYERS):\n",
    "        for j in range(NUM_HEADS):\n",
    "            cur_head = attn_mat[i][j][:LENGTH,:LENGTH]\n",
    "            if not with_eos:\n",
    "                cur_head = cur_head[:-1,:-1]\n",
    "            distance_weighted_median.append(get_mean_distance_weighted_median(cur_head))\n",
    "            globality_scores.append(calc_global_metric(cur_head).item())\n",
    "    \n",
    "    model_distance_weighted_median = sum(distance_weighted_median)/len(distance_weighted_median)\n",
    "    model_globality_scores = sum(globality_scores)/len(globality_scores)\n",
    "    return model_globality_scores, model_distance_weighted_median\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Attention Matrix Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Create Avg Matrix for a range of samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sample_attn_matrix_load(sample_num, model_attn_dir):\n",
    "    '''Stack attn_matrix of all layers to a single matrix that belong to one sample'''\n",
    "    sample_attn_matrix = torch.zeros(NUM_LAYERS,NUM_HEADS,MAX_POSITION,MAX_POSITION)\n",
    "    layers_matricies = []\n",
    "    \n",
    "    batch_size_times_heads = get_batch_size_times_heads(model_attn_dir)\n",
    "    if batch_size_times_heads == NUM_HEADS: # batch size 1\n",
    "        #print(\"batch size 1\")\n",
    "        for i in range(NUM_LAYERS):\n",
    "            cur_index = sample_num*NUM_LAYERS + i\n",
    "            layers_matricies.append(torch.load(model_attn_dir + f'/sample_attn_mat_{cur_index}.pt'))\n",
    "        sample_mat = torch.stack(layers_matricies, dim=0)\n",
    "    else: # batch size is 128\n",
    "        batch_size = int(torch.load(model_attn_dir + f'/sample_attn_mat_0.pt').shape[0]/NUM_HEADS)\n",
    "        #print(f\"batch_size={batch_size}\")\n",
    "        for i in range(NUM_LAYERS):\n",
    "            cur_index = int(sample_num / batch_size)*NUM_LAYERS + i\n",
    "            #print(f\"cur_index={cur_index}\")\n",
    "            loaded_mat = torch.load(model_attn_dir + f'/sample_attn_mat_{cur_index}.pt')\n",
    "            index_in_matrix = (sample_num % batch_size)*NUM_HEADS\n",
    "            #print(f\"index_in_matrix={index_in_matrix}\")\n",
    "            layers_matricies.append(loaded_mat[index_in_matrix:index_in_matrix+NUM_HEADS,:,:])\n",
    "        sample_mat = torch.stack(layers_matricies, dim=0)\n",
    "        #print(f\"sample_mat.shape[-1]={sample_mat.shape[-1]}\")\n",
    "    \n",
    "    sample_attn_matrix[:,:,:sample_mat.shape[-1],:sample_mat.shape[-1]] = sample_mat\n",
    "    \n",
    "    return sample_attn_matrix\n",
    "\n",
    "def get_batch_size_times_heads(model_attn_dir):\n",
    "    try:\n",
    "        sample_matrix = torch.load(model_attn_dir + f'/sample_attn_mat_0.pt')\n",
    "        batch_size_times_heads = sample_matrix.shape[0]\n",
    "    except Exception as e:\n",
    "        list_of_files = glob.glob(f'{model_attn_dir}/avg_attn_mat*') \n",
    "        latest_avg_matrix = max(list_of_files, key=os.path.getctime)\n",
    "        #batch_size_times_heads = int(latest_avg_matrix.split('avg_attn_mat_')[1][:2].replace('_','')) # get the length from the avg mat file name\n",
    "        sample_matrix = torch.load(latest_avg_matrix)\n",
    "        batch_size_times_heads = sample_matrix.shape[1]\n",
    "    return batch_size_times_heads\n",
    "\n",
    "def delete_sample_range_attn_mat(model_attn_dir,samples_range):\n",
    "    batch_size_times_heads = get_batch_size_times_heads(model_attn_dir)\n",
    "    for sample_num in range(samples_range[0], samples_range[1]+1):\n",
    "        if batch_size_times_heads == NUM_HEADS: # batch size 1\n",
    "            for i in range(NUM_LAYERS):\n",
    "                cur_index = sample_num*NUM_LAYERS + i\n",
    "                if os.path.exists(f'{model_attn_dir}/sample_attn_mat_{cur_index}.pt'):\n",
    "                    #print(f\"deleteing... {model_attn_dir}/sample_attn_mat_{cur_index}.pt\")\n",
    "                    os.remove(f'{model_attn_dir}/sample_attn_mat_{cur_index}.pt')\n",
    "           \n",
    "        \n",
    "def get_avg_attn_matrix_load(samples_range, length, NUM_SAMPLES, model_attn_dir, size, cond, cond_name, text_type,recompte_avg_attn_mat=False):\n",
    "    range_name = str(samples_range).replace(' ','_')\n",
    "    saving_name = model_attn_dir + f'/avg_attn_mat_{length}_{range_name}_{size}_{cond}_{cond_name}_{text_type}.pt'\n",
    "    if not recompte_avg_attn_mat:\n",
    "        try:\n",
    "            print(f\"Trying to load: {saving_name}\")\n",
    "            res = torch.load(saving_name)\n",
    "            print(f\"Using saved avg matrix at {saving_name}\")\n",
    "            # delete_sample_range_attn_mat(model_attn_dir,samples_range)\n",
    "            return res\n",
    "        except Exception as e:\n",
    "            print(f\"Exception is:{e}\")\n",
    "            print(\"No saved avg matrix, calculating and saving\")\n",
    "    print(f\"Computing avg matrix for {saving_name}...\")\n",
    "\n",
    "    sum_attn_weights = torch.zeros((NUM_LAYERS,NUM_HEADS,MAX_POSITION,MAX_POSITION)) # layers X attn_heads X max_position X max_position\n",
    "    devision_matrix = torch.zeros((NUM_LAYERS,NUM_HEADS,MAX_POSITION,MAX_POSITION)) # layers X attn_heads X max_position X max_position\n",
    "\n",
    "    for sample_num in range(samples_range[0], samples_range[1]+1):\n",
    "        sample_attn_matrix = get_sample_attn_matrix_load(sample_num, model_attn_dir)\n",
    "        sum_attn_weights += sample_attn_matrix\n",
    "        devision_matrix[sample_attn_matrix!=0] += 1\n",
    "\n",
    "    devision_matrix[devision_matrix==0] = 1\n",
    "    res = sum_attn_weights/devision_matrix\n",
    "    \n",
    "    torch.save(res, saving_name)\n",
    "    print(f\"Saved avg matrix at {saving_name}\")\n",
    "    # delete_sample_range_attn_mat(model_attn_dir,samples_range)\n",
    "    return res\n",
    "\n",
    "def is_eos_focused(sample_attn_matrix):\n",
    "    weight_threshold = 0.20 # 2*1/LENGTH\n",
    "    majority_threshold = 0.80\n",
    "    eos_above_threshold = torch.sum(sample_attn_matrix[:,-1] > weight_threshold)\n",
    "    return (eos_above_threshold / sample_attn_matrix.shape[-1]) > majority_threshold\n",
    "    \n",
    "\n",
    "def get_avg_attn_matrix_across_heads(samples_heads_list, LENGTH, model_attn_dir, ignore_eos=False):\n",
    "    sum_attn_weights = torch.zeros((LENGTH,LENGTH)) \n",
    "    devision_matrix = torch.zeros((LENGTH,LENGTH)) \n",
    "\n",
    "    for score,sample_num,layer,head in samples_heads_list:\n",
    "        sample_attn_matrix = get_sample_attn_matrix_load(sample_num, model_attn_dir)\n",
    "        sample_attn_matrix = sample_attn_matrix[layer][head][:LENGTH,:LENGTH]\n",
    "        if ignore_eos and is_eos_focused(sample_attn_matrix):\n",
    "            continue\n",
    "        sum_attn_weights += sample_attn_matrix\n",
    "        devision_matrix[sample_attn_matrix!=0] += 1\n",
    "    \n",
    "    print(f\"Number of matrices averaged upon: {devision_matrix[0][0]}\")\n",
    "    \n",
    "    devision_matrix[devision_matrix==0] = 1\n",
    "    return sum_attn_weights/devision_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Util Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def calc_percentage_of_attn_head_type(attn_mat, LENGTH, with_eos, weight_threshold=0.35, majority_threshold=0.9):\n",
    "#     print(f\"Attention Weight threshold is: {weight_threshold:.2f}.\")\n",
    "#     print(f\"Majority threshold is: {majority_threshold:.1f}.\")\n",
    "    num_of_eos_foucesed_heads = 0\n",
    "    num_of_local_heads = 0\n",
    "    num_of_self_heads = 0\n",
    "    \n",
    "    eos_foucesed_heads = []\n",
    "    self_heads = []\n",
    "    local_heads = []\n",
    "    distance_weighted_median = []\n",
    "    globality_scores = []\n",
    "    \n",
    "    for i in range(NUM_LAYERS):\n",
    "        for j in range(NUM_HEADS):\n",
    "            cur_head = attn_mat[i][j][:LENGTH,:LENGTH]\n",
    "            if not with_eos:\n",
    "                cur_head = cur_head[:-1,:-1]\n",
    "            \n",
    "            # EOS-focused\n",
    "            eos_foucesed_heads.append(np.percentile(cur_head[:,-1], 90))\n",
    "            eos_above_threshold = torch.sum(cur_head[:,-1] > weight_threshold)\n",
    "            #eos_foucesed_heads.append(torch.mean(cur_head[:,-1]))\n",
    "            if (eos_above_threshold / cur_head.shape[-1]) > majority_threshold:\n",
    "                num_of_eos_foucesed_heads += 1\n",
    "                \n",
    "            # Self-focused\n",
    "            self_heads.append(np.percentile(cur_head.diagonal(), 90))\n",
    "            self_above_threshold = torch.sum(cur_head.diagonal() > weight_threshold)\n",
    "            if (self_above_threshold / cur_head.shape[-1]) > majority_threshold:\n",
    "                num_of_self_heads += 1\n",
    "                \n",
    "            # Local-focused\n",
    "            local_mean = (cur_head.diagonal()[1:-1] + cur_head.diagonal(1)[1:] + cur_head.diagonal(-1)[:-1])#/3\n",
    "            pos_first_local_mean = (cur_head.diagonal()[0] + cur_head.diagonal(1)[0]) #/ 2\n",
    "            pos_last_local_mean = (cur_head.diagonal()[-1] + cur_head.diagonal(-1)[-1]) #/ 2\n",
    "            local_mean = torch.cat([pos_first_local_mean.unsqueeze(0),local_mean,pos_last_local_mean.unsqueeze(0)])\n",
    "            \n",
    "            local_mean -= cur_head.diagonal() # do not include self attention\n",
    "            \n",
    "            local_heads.append(np.percentile(local_mean, 90))\n",
    "            local_above_threshold = torch.sum(cur_head.diagonal() > weight_threshold)\n",
    "            if (local_above_threshold / cur_head.shape[-1]) > majority_threshold:\n",
    "                num_of_local_heads += 1\n",
    "            \n",
    "            # Weighted median distance & Globality\n",
    "            distance_weighted_median.append(get_mean_distance_weighted_median(cur_head))\n",
    "            globality_scores.append(calc_global_metric(cur_head).item())\n",
    "\n",
    "    print(\"Percentage of EOS focused heads:  {:.2%}\".format(num_of_eos_foucesed_heads/(NUM_LAYERS*NUM_LAYERS)), end=' | ')\n",
    "    print(\"Percentage of self focused heads: {:.2%}\".format(num_of_self_heads/(NUM_LAYERS*NUM_LAYERS)), end=' | ')\n",
    "    print(\"Percentage of Local focused heads: {:.2%}\".format(num_of_local_heads/(NUM_LAYERS*NUM_LAYERS)))\n",
    "    \n",
    "    return eos_foucesed_heads, self_heads, local_heads, distance_weighted_median, globality_scores\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_samples_from_prints():\n",
    "    all_samples = dict()\n",
    "    with open(fname, 'r') as f:\n",
    "        sample_num = 0\n",
    "        line = f.readline()\n",
    "        while len(line) != 0: # not EOF\n",
    "            if '</s>' in line:\n",
    "                all_samples[sample_num] = line\n",
    "                #print(str(sample_num)+line)\n",
    "                sample_num += 1\n",
    "            line = f.readline()\n",
    "    return all_samples\n",
    "                            \n",
    "def get_all_samples_dict(fname):\n",
    "    print(f\"getting samples dict from: {fname}\")\n",
    "    all_samples = dict()\n",
    "    with open(fname, 'r') as f:\n",
    "        sample_num = 0\n",
    "        line = f.readline()\n",
    "        while len(line) != 0: # not EOF\n",
    "            if 'S-' in line:\n",
    "                all_samples[sample_num] = line.split(' ')#[1:]\n",
    "                #print(str(sample_num)+line)\n",
    "                sample_num += 1\n",
    "            line = f.readline()\n",
    "    return all_samples\n",
    "\n",
    "def get_sample_len(sample_num, model_attn_dir, num_of_samples):\n",
    "    try:\n",
    "        sample_matrix = torch.load(model_attn_dir + f'/sample_attn_mat_{sample_num}.pt')\n",
    "    except Exception as e: # there's exists a saved lengths dict\n",
    "        lengths_dict = get_samples_lengths_dict(num_of_samples, model_attn_dir)\n",
    "        \n",
    "        for length in lengths_dict.keys():\n",
    "            loading_name = f'{model_attn_dir}/{length}_range_tuple.pt'\n",
    "            loaded_range = torch.load(loading_name)\n",
    "            if (loaded_range[length][0] <= sample_num) or (sample_num <= loaded_range[length][1]):\n",
    "                return length\n",
    "    \n",
    "    if sample_matrix.shape[0] == 8: # batch size 1\n",
    "        index = sample_num*NUM_LAYERS\n",
    "    else: # batch size 128\n",
    "        batch_size = int(torch.load(model_attn_dir + f'/sample_attn_mat_{sample_num}.pt').shape[0]/NUM_HEADS)\n",
    "        index = int(sample_num / batch_size)*NUM_LAYERS \n",
    "    attn_mat = torch.load(model_attn_dir+f'/sample_attn_mat_{index}.pt')\n",
    "    return attn_mat.shape[-1]\n",
    "\n",
    "def display_sample(LAYER, HEAD, sample_num, all_samples, model_attn_dir, print_out=True):\n",
    "    sample_attn_matrix = get_sample_attn_matrix_load(sample_num, model_attn_dir)\n",
    "    sample, sample_len = all_samples[sample_num].copy(), get_sample_len(sample_num, model_attn_dir, len(all_samples))\n",
    "    \n",
    "    sample[0] = sample[0].split('\\t')[1]\n",
    "    sample[-1] = '.'\n",
    "    sample.append('EOS')\n",
    "\n",
    "\n",
    "    gm_score = calc_global_metric(sample_attn_matrix[LAYER][HEAD][:sample_len,:sample_len]).item()\n",
    "    w_median = get_mean_distance_weighted_median(sample_attn_matrix[LAYER][HEAD][:sample_len,:sample_len])\n",
    "    \n",
    "    if print_out:\n",
    "        print(' '.join(sample))\n",
    "        print(f\"LAYER={LAYER}, HEAD={HEAD}\")\n",
    "        ax = sns.heatmap(sample_attn_matrix[LAYER][HEAD][:sample_len,:sample_len], xticklabels=sample, yticklabels=sample)\n",
    " \n",
    "        ax.set(title=\"Attention Heatmap\",\n",
    "          xlabel=\"Attention To\",\n",
    "          ylabel=\"Attention From\",)\n",
    "        \n",
    "        plt.rcParams[\"figure.figsize\"] = (6,4.5)\n",
    "        plt.show()\n",
    "        print(\"Global Metric = {:.2f}\".format(gm_score))\n",
    "        print(\"Weighted Median = {:.2f}\".format(w_median))\n",
    "    \n",
    "    return gm_score, w_median \n",
    "    \n",
    "def get_samples_lengths_dict(num_of_samples, model_attn_dir):\n",
    "    saving_name = f'{model_attn_dir}/lengths_dict.pt'\n",
    "    if os.path.exists(saving_name):\n",
    "        print(f\"Loading lengths_dict from: {model_attn_dir}\")\n",
    "        return torch.load(saving_name)\n",
    "                          \n",
    "    print(f\"Creating new lengths_dict for: {model_attn_dir}\")\n",
    "    samples_legnth = dict()\n",
    "    for sample_num in range(num_of_samples):\n",
    "        cur_len = get_sample_len(sample_num, model_attn_dir, num_of_samples)\n",
    "        if cur_len in samples_legnth:\n",
    "            samples_legnth[cur_len] += 1\n",
    "        else:\n",
    "            samples_legnth[cur_len] = 1\n",
    "                          \n",
    "    torch.save(samples_legnth,saving_name)\n",
    "    return samples_legnth\n",
    "\n",
    "    \n",
    "def get_samples_range(target_length, num_of_samples, model_attn_dir):\n",
    "    saving_name = f'{model_attn_dir}/{target_length}_range_tuple.pt'\n",
    "    if os.path.exists(saving_name):\n",
    "        return torch.load(saving_name)[target_length]\n",
    "    \n",
    "    samples_cur_legnth = []\n",
    "    for sample_num in range(num_of_samples):\n",
    "        cur_len = get_sample_len(sample_num, model_attn_dir, num_of_samples)    \n",
    "        #print(f\"sample_num:{sample_num} | cur_len:{cur_len}\")\n",
    "        if cur_len == target_length:\n",
    "            samples_cur_legnth.append(sample_num)\n",
    "    if len(samples_cur_legnth) == 0:\n",
    "        raise Exception(f'No samples found with length {target_length} for model at {model_attn_dir}.')\n",
    "    res = {target_length: (samples_cur_legnth[0],samples_cur_legnth[-1])}\n",
    "    torch.save(res, saving_name)\n",
    "    return res[target_length]\n",
    "\n",
    "def get_bleu_score(trained_model, size):\n",
    "    list_of_files = glob.glob(f'/checkpoint/itayitzhak/trained_models/opus/{size}/{trained_model}/eval*out*') \n",
    "    latest_file = max(list_of_files, key=os.path.getctime)\n",
    "    with open(latest_file, 'r') as f:\n",
    "        for line in f.readlines():\n",
    "            if 'BLEU4' in line:\n",
    "                return float(line.split('BLEU4')[1][3:8].strip().replace(',',''))\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Compare sampels from different model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LAYER = 5\n",
    "# HEAD = 0\n",
    "# sample_num = 100\n",
    "\n",
    "# seed_mod = '1'\n",
    "# seed_data = '1'\n",
    "# size = 'all' # 'all'\n",
    "# cond = 's_conj' #'s_np_vp'\n",
    "# cond_name = 's1_s2'#'np'\n",
    "# data_type = 'synthetic' #'semi_natural' #'natural'\n",
    "# premuted_prefix = 'compositional_mt_'#'permuted_data_' # ''\n",
    "# premuted_suffix = ''#'_3gram' # ''\n",
    "# LENGTH = 17\n",
    "# NUM_HEADS = 8\\\\\n",
    "# NUM_LAYERS = 6\n",
    "# MAX_POSITION = 1024\n",
    "# #############################\n",
    "# cur_model_path = f'/checkpoint/itayitzhak/attn_weigths/{premuted_prefix}systematicity_{cond}_{data_type}_systematicity_{data_type}_{seed_data}_{cond_name}{premuted_suffix}_{size}'\n",
    "# #cur_model_pred = f'/checkpoint/itayitzhak/attn_weigths/systematicity_s_conj_synthetic_systematicity_synthetic_1_s1_s2_all/generate-test.txt'\n",
    "# cur_model_pred = f'/checkpoint/itayitzhak/attn_weigths/compositional_mt_systematicity_{cond}_{data_type}_systematicity_{data_type}_{seed_data}_{cond_name}_all/generate-test.txt'\n",
    "# if 'permuted' in premuted_prefix:\n",
    "#     cur_model_pred = f'/checkpoint/itayitzhak/permuted_data/systematicity/{cond}/{data_type}/systematicity_{data_type}_{seed_data}_{cond_name}{premuted_suffix}/all/pred.txt/generate-test.txt'\n",
    "# all_samples = get_all_samples_dict(cur_model_pred)\n",
    "\n",
    "# NUM_SAMPLES = len(all_samples)\n",
    "\n",
    "# Per sample\n",
    "# display_sample(LAYER, HEAD, sample_num, all_samples, cur_model_path)\n",
    "# #bla = cur_model_path.split('/')[-1]\n",
    "# print(f\"Model:{cur_model_path}\")\n",
    "# print(f\"Predi:{cur_model_pred}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Per layer\n",
    "# LAYER = 4\n",
    "#sns.heatmap(avg_attn_matrix[LAYER].mean(dim=0)[:LENGTH,:LENGTH])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Per head\n",
    "# LAYER = 4\n",
    "# HEAD = 7\n",
    "# sns.heatmap(avg_attn_matrix[LAYER][HEAD][:LENGTH,:LENGTH])\n",
    "# print(\"Global Metric = {:.2f}\".format(calc_global_metric(avg_attn_matrix[LAYER][HEAD][:LENGTH,:LENGTH]).item()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Compute Consistency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import pickle\n",
    "import numpy as np\n",
    "import editdistance\n",
    "\n",
    "\n",
    "def get_conjunct(sentence):\n",
    "    \"\"\"\n",
    "    Separate sentence into two parts based on conjunction.\n",
    "    Args:\n",
    "        - sentence (str)\n",
    "    Returns:\n",
    "        - whether the conjunct was found\n",
    "        - the conjunct\n",
    "    \"\"\"\n",
    "    conjunction = \" en \"\n",
    "\n",
    "    # If conjunct in sentence\n",
    "    if conjunction in sentence:\n",
    "        conjunct = sentence.split(conjunction)[1:]\n",
    "        # If the conjunct is shorter than 3 words you've got the wrong one\n",
    "        if len(sentence.split(conjunction)[0].split()) < 3:\n",
    "            conjunct = sentence.split(conjunction)[2:]\n",
    "        conjunct = conjunction.join(conjunct)\n",
    "        return True, f\"MASK {conjunct}\"\n",
    "    return False, f\"MASK {sentence}\"\n",
    "\n",
    "\n",
    "def reorder(lines):\n",
    "    \"\"\"\n",
    "    Reorder lines, since Fairseq shuffles them while translating.\n",
    "    Order based on the index indicated after \"D-...\", \"S-...\" or \"H-...\".\n",
    "    \n",
    "    Args:\n",
    "        - lines: list of str\n",
    "    Returns:\n",
    "        - list of str\n",
    "    \"\"\"\n",
    "    sentences = []\n",
    "    for line in lines:\n",
    "        line = line.split(\"\\t\")\n",
    "        if \"D-\" in line[0]:\n",
    "            index = int(line[0].split('-')[1])\n",
    "            sentence = line[2].strip()\n",
    "            sentences.append((index, sentence))\n",
    "    _, sentences = zip(*sorted(sentences))\n",
    "    assert len(sentences) == 500\n",
    "    return sentences\n",
    "\n",
    "\n",
    "def compute_systematicity_s_conj_globality(template, seed, expirement_data_type, text_type, data_size):\n",
    "    \"\"\"\n",
    "    Compute systematicity consistency scores for the S -> S CONJ S setup.\n",
    "    Args:\n",
    "        - template (int): 1 ... 10\n",
    "        - data_type (str): natural | semi_natural | synthetic\n",
    "        - model (str): format of \"transformer_DATA_SEED\"\n",
    "    Returns:\n",
    "        - s1p (float): consistency score for the S1 -> S1' condition\n",
    "        - s3 (float): consistency score for the S1 -> S3 condition\n",
    "        - trace (dict): mistakes made by the model\n",
    "    \"\"\"\n",
    "    trace = dict()\n",
    "    condition_s1p = []\n",
    "    condition_s3 = []\n",
    "    #prefix = f\"s_conj/{data_type}/systematicity_{data_type}_{template}\"\n",
    "    home_dir = '/checkpoint/itayitzhak/attn_weigths/'\n",
    "    source_file_prefix = f'/private/home/dieuwkehupkes/nmt/compositional_mt/systematicity/s_conj/{text_type}/systematicity_{text_type}_{template}'\n",
    "\n",
    "    # English source sentences\n",
    "#     with open(f\"{prefix}_s1_s2.en\", encoding=\"utf-8\") as f:\n",
    "#         srcs = f.readlines()\n",
    "    with open(f\"{source_file_prefix}_s1_s2.en\", encoding=\"utf-8\") as f:\n",
    "        srcs = f.readlines()\n",
    "    \n",
    "    # Gather the translation of the regular setup and the two subconditions\n",
    "    # prefix = f\"s_conj/pred_{data_type}/{model}/systematicity_{data_type}_{template}\"\n",
    "    #with open(f\"{prefix}_s1_s2.nl\", encoding=\"utf-8\") as f:\n",
    "    try:\n",
    "        with open(f\"{home_dir}{expirement_data_type}_seed_{seed}_compositional_mt_systematicity_s_conj_{text_type}_systematicity_{text_type}_{template}_s1_s2_{data_size}/generate-test.txt\", encoding=\"utf-8\") as f:\n",
    "            pred_s1_s2 = reorder(f.readlines())\n",
    "    except Exception as e:\n",
    "        raise Exception(\"Could not load pred_s1_s2 at {{home_dir}{expirement_data_type}_seed_{seed}_compositional_mt_systematicity_s_conj_{text_type}_systematicity_{text_type}_{template}_s1_s2_{data_size}/generate-test.txt}\\n\"+str(e))\n",
    "    \n",
    "    try:\n",
    "        #with open(f\"{prefix}_s1p_s2.nl\", encoding=\"utf-8\") as f:\n",
    "        with open(f\"{home_dir}{expirement_data_type}_seed_{seed}_compositional_mt_systematicity_s_conj_{text_type}_systematicity_{text_type}_{template}_s1p_s2_{data_size}/generate-test.txt\", encoding=\"utf-8\") as f:\n",
    "            pred_s1p_s2 = reorder(f.readlines())\n",
    "    except Exception as e:\n",
    "        raise Exception(\"Could not load pred_s1p_s2 at {{home_dir}{expirement_data_type}_seed_{seed}_compositional_mt_systematicity_s_conj_{text_type}_systematicity_{text_type}_{template}_s1p_s2_{data_size}/generate-test.txt}\\n\"+str(e))\n",
    "        \n",
    "    try:\n",
    "        #with open(f\"{prefix}_s3_s2.nl\", encoding=\"utf-8\") as f:\n",
    "        with open(f\"{home_dir}{expirement_data_type}_seed_{seed}_compositional_mt_systematicity_s_conj_{text_type}_systematicity_{text_type}_{template}_s3_s2_{data_size}/generate-test.txt\", encoding=\"utf-8\") as f:\n",
    "            pred_s3_s2 = reorder(f.readlines())\n",
    "    except Exception as e:\n",
    "        raise Exception(\"Could not load pred_s3_s2 at {{home_dir}{expirement_data_type}_seed_{seed}_compositional_mt_systematicity_s_conj_{text_type}_systematicity_{text_type}_{template}_s3_s2_{data_size}/generate-test.txt}\\n\"+str(e))\n",
    "\n",
    "    for src, first, second, third in zip(srcs, pred_s1_s2, pred_s1p_s2, pred_s3_s2):\n",
    "        # Ensure that the same type of tokenisation is used \n",
    "        found1, first_conjunct = get_conjunct(first)\n",
    "        found2, second_conjunct = get_conjunct(second)\n",
    "        found3, third_conjunct = get_conjunct(third)\n",
    "\n",
    "        # Don't consider sentences where the second conjunct was not found\n",
    "        if not all([found1, found2, found3]):\n",
    "            continue\n",
    "\n",
    "        condition_s1p.append(first_conjunct == second_conjunct)\n",
    "        condition_s3.append(first_conjunct == third_conjunct)\n",
    "\n",
    "        # Collect cases where s2 different for s1' and s3 substitutions\n",
    "        if first_conjunct not in {second_conjunct, third_conjunct}:\n",
    "            trace[src.strip()] = (first_conjunct, second_conjunct, third_conjunct)\n",
    "\n",
    "    s1p = np.mean(condition_s1p)\n",
    "    s3 = np.mean(condition_s3)\n",
    "    return (s1p, s3), trace, condition_s1p, condition_s3\n",
    "\n",
    "\n",
    "def compute_systematicity_s_np_vp_globality(template, seed, expirement_data_type, text_type, data_size):\n",
    "    \"\"\"\n",
    "    Compute systematicity consistency scores for the S -> NP VP setup.\n",
    "    Args:\n",
    "        - template (int): 1 ... 10\n",
    "        - data_type (str): natural | semi_natural | synthetic\n",
    "        - model (str): format of \"transformer_DATA_SEED\"\n",
    "    Returns:\n",
    "        - score_np (float): consistency score for the NP -> NP' condition\n",
    "        - score_vp (float): consistency score for the VP -> VP' condition\n",
    "        - trace (dict): mistakes made by the model\n",
    "    \"\"\"\n",
    "    trace = dict()\n",
    "    condition_np = []\n",
    "    condition_vp = []\n",
    "    # prefix = f\"s_np_vp/{data_type}/systematicity_{data_type}_{template}\"\n",
    "    #with open(f\"{prefix}_np.en\", encoding=\"utf-8\") as f:\n",
    "    home_dir = '/checkpoint/itayitzhak/attn_weigths/'\n",
    "    source_file_prefix = f'/private/home/dieuwkehupkes/nmt/compositional_mt/systematicity/s_np_vp/{text_type}/systematicity_{text_type}_{template}'\n",
    "    with open(f\"{source_file_prefix}_np.en\", encoding=\"utf-8\") as f:\n",
    "        np_srcs = f.readlines()\n",
    "    #with open(f\"{prefix}_np_prime.en\", encoding=\"utf-8\") as f:\n",
    "    with open(f\"{source_file_prefix}_np_prime.en\", encoding=\"utf-8\") as f:   \n",
    "        np_srcs_prime = f.readlines()\n",
    "    if text_type == \"synthetic\":\n",
    "        #with open(f\"{prefix}_vp_prime.en\", encoding=\"utf-8\") as f:\n",
    "        with open(f\"{source_file_prefix}_vp_prime.en\", encoding=\"utf-8\") as f:\n",
    "            vp_srcs_prime = f.readlines()\n",
    "    \n",
    "    # prefix = f\"s_np_vp/pred_{data_type}/{model}/systematicity_{data_type}_{template}\"\n",
    "    #with open(f\"{prefix}_np.nl\", encoding=\"utf-8\") as f:\n",
    "    with open(f\"{home_dir}{expirement_data_type}_seed_{seed}_compositional_mt_systematicity_s_np_vp_{text_type}_systematicity_{text_type}_{template}_np_{data_size}/generate-test.txt\", encoding=\"utf-8\") as f:\n",
    "        pred_np = reorder(f.readlines())\n",
    "    #with open(f\"{prefix}_np_prime.nl\", encoding=\"utf-8\") as f:\n",
    "    with open(f\"{home_dir}{expirement_data_type}_seed_{seed}_compositional_mt_systematicity_s_np_vp_{text_type}_systematicity_{text_type}_{template}_np_prime_{data_size}/generate-test.txt\", encoding=\"utf-8\") as f:\n",
    "        pred_np_prime = reorder(f.readlines())\n",
    "    if text_type == \"synthetic\":\n",
    "        #with open(f\"{prefix}_vp_prime.nl\", encoding=\"utf-8\") as f:\n",
    "        with open(f\"{home_dir}{expirement_data_type}_seed_{seed}_compositional_mt_systematicity_s_np_vp_{text_type}_systematicity_{text_type}_{template}_vp_prime_{data_size}/generate-test.txt\", encoding=\"utf-8\") as f:\n",
    "            pred_vp_prime = reorder(f.readlines())\n",
    "\n",
    "    for k, (src, src_prime, sent, np_prime) in enumerate(zip(np_srcs, np_srcs_prime, pred_np, pred_np_prime)):\n",
    "        sent = sent.replace(\" het \", \" de \").replace(\"Het \", \"De \").replace(\" dat \", \" die \")\n",
    "        np_prime = np_prime.replace(\" het \", \" de \").replace(\"Het \", \"De \").replace(\" dat \", \" die \")\n",
    "        \n",
    "        condition_np.append(editdistance.eval(sent.split(), np_prime.split()) == 1)\n",
    "        if editdistance.eval(sent.split(), np_prime.split()) != 1:\n",
    "            trace[(src.strip(), src_prime, \"np\")] = (sent, np_prime)\n",
    "\n",
    "        if text_type == \"synthetic\":\n",
    "            vp_prime = pred_vp_prime[k].replace(\" het \", \" de \").replace(\"Het \", \"De \").replace(\" dat \", \" die \")\n",
    "            vp_prime = vp_prime.replace(\" het \", \" de \").replace(\"Het \", \"De \").replace(\" dat \", \" die \")\n",
    "            condition_vp.append(editdistance.eval(sent.split(), vp_prime.split()) == 1)\n",
    "            if editdistance.eval(sent.split(), vp_prime.split()) != 1:\n",
    "                trace[(np_srcs[k].strip(), vp_srcs_prime[k], \"vp\")] = (sent, vp_prime)\n",
    "\n",
    "    # Report results to user in a format that can easily be copied to tables\n",
    "    score_np = np.mean(condition_np)\n",
    "    score_vp = None if text_type != \"synthetic\" else np.mean(condition_vp)\n",
    "    return (score_np, score_vp), trace, condition_np, condition_vp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_consistencies_per_sample(systematicity_trace, samples_range, all_samples, template, seed, trained_data_type, text_type, trained_data_size):\n",
    "    consistencies = []\n",
    "    for i, sample in enumerate(all_samples):\n",
    "        #src_sent = get_src_sent(sample_num, template, seed, trained_data_type, text_type, trained_data_size)\n",
    "        consistencies.append(systematicity_trace[sample.strip()])\n",
    "    return consistencies\n",
    "    \n",
    "def reorder_consistency(all_s1_p, cur_model_pred):\n",
    "    ordered_consistency = []\n",
    "    \n",
    "    with open(cur_model_pred, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "        \n",
    "    for sample_num,line in enumerate(lines):\n",
    "        line = line.split(\"\\t\")\n",
    "        if 'S-' in line[0]:\n",
    "            index = int(line[0].split('-')[1])\n",
    "            ordered_consistency.append(all_s1_p[index])\n",
    "    \n",
    "    assert len(ordered_consistency) == 500\n",
    "    return ordered_consistency\n",
    "\n",
    "\n",
    "def get_all_samples_globality_and_wmd(model_attn_dir, NUM_SAMPLES, lengths_dict, with_eos):\n",
    "    all_g, all_w = [], []\n",
    "    \n",
    "    for sample_num in range(NUM_SAMPLES):\n",
    "        sample_attn_matrix = get_sample_attn_matrix_load(sample_num, model_attn_dir)\n",
    "        length = get_sample_len(sample_num, model_attn_dir, NUM_SAMPLES)\n",
    "        g, w = get_model_wmd_gloablity_scores(sample_attn_matrix, length, with_eos=with_eos)  \n",
    "        all_g.append(g)\n",
    "        all_w.append(w)\n",
    "    return all_g, all_w"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### All models results analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_seed_final_results(curr_model_final_results, seed, trained_data_size, trained_data_type, text_type, conds, template, premuted_prefix, premuted_suffix, is_with_eos, consistency_only, is_fine_grained_gloablities):\n",
    "    cur_model_path = f'/checkpoint/itayitzhak/attn_weigths/{trained_data_type}_seed_{seed}_{premuted_prefix}systematicity_{conds[0]}_{text_type}_systematicity_{text_type}_{template}_{conds[1]}{premuted_suffix}_{trained_data_size}'\n",
    "    cur_model_pred = cur_model_path + f'/generate-test.txt'\n",
    "    \n",
    "    all_samples = get_all_samples_dict(cur_model_pred)\n",
    "    NUM_SAMPLES = len(all_samples)\n",
    "    lengths_dict = get_samples_lengths_dict(NUM_SAMPLES, cur_model_path)\n",
    "    curr_model_final_results['lengths_dict'] = lengths_dict\n",
    "    print(f\"lengths_dict:{lengths_dict}\")\n",
    "\n",
    "    if conds[0] == 's_conj' and conds[1] == 's1_s2':\n",
    "        (s1p, s3), systematicity_trace, all_s1_p, all_s3 = compute_systematicity_s_conj_globality(template, seed, trained_data_type, text_type, trained_data_size)\n",
    "        curr_model_final_results['s_conj_s1p_s2_consist'].append(s1p)\n",
    "        curr_model_final_results['s_conj_s3_s2_consist'].append(s3)\n",
    "        # print(f\"len(all_s1_p)={len(all_s1_p)}\")\n",
    "        # curr_model_final_results['all_sampels_s_conj_s1p_s2_consist'].append(reorder_consistency(all_s1_p, cur_model_pred))\n",
    "        # curr_model_final_results['all_sampels_s_conj_s3_s2_consist'].append(reorder_consistency(all_s3, cur_model_pred))\n",
    "        # curr_model_final_results['all_sampels_s_conj_s1p_s2_consist'].extend(all_s1_p) # just for test\n",
    "        # curr_model_final_results['all_sampels_s_conj_s3_s2_consist'].extend(all_s3)\n",
    "    elif conds[0] == 's_np_vp' and conds[1] == 'np':\n",
    "        (score_np, score_vp), systematicity_trace, all_np, all_vp = compute_systematicity_s_np_vp_globality(template, seed, trained_data_type, text_type, trained_data_size)\n",
    "        curr_model_final_results['s_np_vp_np_prime_consist'].append(score_np)\n",
    "        curr_model_final_results['s_np_vp_vp_prime_consist'].append(score_vp)\n",
    "        \n",
    "    curr_model_final_results['model_bleu'].append(get_bleu_score(f'{trained_data_type}_seed_{seed}', trained_data_size))\n",
    "    \n",
    "    if is_fine_grained_gloablities: # get all globalities scores\n",
    "        all_g, all_w = get_all_samples_globality_and_wmd(cur_model_path, NUM_SAMPLES, lengths_dict, is_with_eos)\n",
    "        curr_model_final_results['all_sampels_gloablity'].append(all_g)\n",
    "        curr_model_final_results['all_sampels_weighted_median_distance'].append(all_w)\n",
    "        # curr_model_final_results['all_sampels_gloablity'].extend(all_g)\n",
    "        # curr_model_final_results['all_sampels_weighted_median_distance'].extend(all_w)\n",
    "    \n",
    "    if consistency_only:\n",
    "        return curr_model_final_results\n",
    "\n",
    "    curr_seed_model_wmd = []\n",
    "    curr_seed_model_glob = []\n",
    "    \n",
    "    for length in lengths_dict.keys():\n",
    "        LENGTH = length\n",
    "        samples_range = get_samples_range(LENGTH, NUM_SAMPLES, cur_model_path)\n",
    "        avg_attn_matrix = get_avg_attn_matrix_load(samples_range, length, NUM_SAMPLES, cur_model_path, trained_data_size, conds[0], conds[1], text_type, recompte_avg_attn_mat)\n",
    "        g, w = get_model_wmd_gloablity_scores(avg_attn_matrix, LENGTH, with_eos=is_with_eos)\n",
    "        eos_foucesed_heads, self_heads, local_heads, distance_weighted_median, globality_scores = calc_percentage_of_attn_head_type(\n",
    "        avg_attn_matrix, LENGTH, with_eos=is_with_eos)\n",
    "        #consistencies = get_consistencies_per_sample(systematicity_trace, samples_range, all_samples, template, seed, trained_data_type, text_type, trained_data_size)\n",
    "\n",
    "        curr_model_final_results['eos_foucesed_heads'].append(eos_foucesed_heads)\n",
    "        curr_model_final_results['self_heads'].append(self_heads)\n",
    "        curr_model_final_results['local_heads'].append(local_heads)\n",
    "        curr_model_final_results['distance_weighted_median'].append(distance_weighted_median)\n",
    "        curr_model_final_results['globality_scores'].append(globality_scores)\n",
    "\n",
    "        curr_seed_model_wmd.append(w)\n",
    "        curr_seed_model_glob.append(g)\n",
    "\n",
    "    curr_model_final_results['model_distance_weighted_median'].append(np.average(curr_seed_model_wmd, weights=list(lengths_dict.values())))\n",
    "    curr_model_final_results['model_globality_scores'].append(np.average(curr_seed_model_glob, weights=list(lengths_dict.values())))\n",
    "    \n",
    "    return curr_model_final_results\n",
    "    \n",
    "    \n",
    "def get_model_final_results(all_seeds, trained_data_size, trained_data_type, text_type, conds, template, premuted_prefix, premuted_suffix, consistency_only, is_fine_grained_gloablities):\n",
    "    curr_model_final_results = {'eos_foucesed_heads':[],\n",
    "                                'self_heads':[],\n",
    "                                'local_heads':[],\n",
    "                               'distance_weighted_median':[],\n",
    "                                'globality_scores':[],\n",
    "                               'trained_data_type':trained_data_type,\n",
    "                               'trained_data_size':trained_data_size,\n",
    "                               'conds':conds,\n",
    "                               'text_type':text_type,\n",
    "                                'template': template,\n",
    "                               'model_bleu':[],\n",
    "                               'model_distance_weighted_median':[],\n",
    "                               'model_globality_scores':[],\n",
    "                               'all_sampels_gloablity':[],\n",
    "                                'all_sampels_weighted_median_distance':[]\n",
    "                               }\n",
    "\n",
    "    size = trained_data_size\n",
    "    cond = conds[0]\n",
    "    cond_name = conds[1]\n",
    "\n",
    "    if cond == 's_conj': # and cond_name == 's1p':\n",
    "        curr_model_final_results['s_conj_s1p_s2_consist'] = []\n",
    "        curr_model_final_results['s_conj_s3_s2_consist'] = []\n",
    "        curr_model_final_results['all_sampels_s_conj_s1p_s2_consist'] = []\n",
    "        curr_model_final_results['all_sampels_s_conj_s3_s2_consist'] = []\n",
    "    elif cond == 's_np_vp':\n",
    "        curr_model_final_results['s_np_vp_np_prime_consist'] = []\n",
    "        curr_model_final_results['s_np_vp_vp_prime_consist'] = []\n",
    "        curr_model_final_results['all_sampels_s_np_vp_np_prime_consist'] = []\n",
    "        curr_model_final_results['all_sampels_s_np_vp_vp_prime_consist'] = []\n",
    "\n",
    "    if trained_data_type == 'not_permuted_without_eos':\n",
    "        trained_data_type = 'not_permuted'\n",
    "        is_with_eos = False\n",
    "    else:\n",
    "        is_with_eos = True\n",
    "\n",
    "    for seed in all_seeds:\n",
    "        curr_model_final_results = get_seed_final_results(curr_model_final_results.copy(), seed, trained_data_size, trained_data_type, text_type, conds, template, premuted_prefix, premuted_suffix, is_with_eos, consistency_only, is_fine_grained_gloablities)\n",
    "\n",
    "    return curr_model_final_results\n",
    "\n",
    "\n",
    "def get_all_models_final_results(all_data_types,all_data_sizes,all_text_type,all_conds,all_seeds,all_templates,recompte_avg_attn_mat=True, consistency_only=False, is_fine_grained_gloablities=False):\n",
    "    all_models_final_results = dict()\n",
    "    premuted_prefix = 'compositional_mt_'#'permuted_data_' #'compositional_mt_' for non-permuted#\n",
    "    premuted_suffix = ''#'_3gram' # ''\n",
    "    \n",
    "    saving_name = f'/checkpoint/itayitzhak/attn_weigths/all_models_final_results_{str(all_data_types)}_{str(all_data_sizes)}_{str(all_text_type)}_{str(all_conds)}_{str(all_seeds)}_{str(all_templates)}_{str(recompte_avg_attn_mat)}'\n",
    "#     if os.path.exists(saving_name):\n",
    "#         return torch.load(saving_name)\n",
    "    i = 0\n",
    "    for trained_data_size, trained_data_type, text_type, conds, template in list(\n",
    "        itertools.product(all_data_sizes, all_data_types, all_text_type, all_conds, all_templates)):\n",
    "        curr_model_final_results = get_model_final_results(all_seeds, trained_data_size, trained_data_type, text_type, conds, template, premuted_prefix, premuted_suffix, consistency_only, is_fine_grained_gloablities)\n",
    "        model_name_to_save = f\"{curr_model_final_results['trained_data_type']}_{trained_data_size}_{text_type}_{conds}_{template}_{premuted_prefix}_{premuted_suffix}\"\n",
    "        # cur_model_path = f'/checkpoint/itayitzhak/attn_weigths/{trained_data_type}_seed_{seed}_{premuted_prefix}systematicity_{conds[0]}_{text_type}_systematicity_{text_type}_{template}_{conds[1]}{premuted_suffix}_{trained_data_size}'\n",
    "        all_models_final_results[model_name_to_save] = curr_model_final_results\n",
    "        print('='*100)\n",
    "        i += 1\n",
    "        print(f\"Model {i}/{len(list(itertools.product(all_data_sizes, all_data_types, all_text_type, all_conds, all_templates)))}\")\n",
    "        print('='*100)\n",
    "    \n",
    "    torch.save(all_models_final_results,saving_name)\n",
    "    return all_models_final_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting samples dict from: /checkpoint/itayitzhak/attn_weigths/not_permuted_seed_4_compositional_mt_systematicity_s_conj_synthetic_systematicity_synthetic_1_s1_s2_tiny/generate-test.txt\n",
      "Loading lengths_dict from: /checkpoint/itayitzhak/attn_weigths/not_permuted_seed_4_compositional_mt_systematicity_s_conj_synthetic_systematicity_synthetic_1_s1_s2_tiny\n",
      "lengths_dict:{15: 15, 16: 68, 17: 119, 18: 146, 19: 85, 20: 44, 21: 17, 22: 5, 23: 1}\n",
      "Trying to load: /checkpoint/itayitzhak/attn_weigths/not_permuted_seed_4_compositional_mt_systematicity_s_conj_synthetic_systematicity_synthetic_1_s1_s2_tiny/avg_attn_mat_15_(0,_14)_tiny_s_conj_s1_s2_synthetic.pt\n",
      "Using saved avg matrix at /checkpoint/itayitzhak/attn_weigths/not_permuted_seed_4_compositional_mt_systematicity_s_conj_synthetic_systematicity_synthetic_1_s1_s2_tiny/avg_attn_mat_15_(0,_14)_tiny_s_conj_s1_s2_synthetic.pt\n",
      "Percentage of EOS focused heads:  0.00% | Percentage of self focused heads: 0.00% | Percentage of Local focused heads: 0.00%\n",
      "Trying to load: /checkpoint/itayitzhak/attn_weigths/not_permuted_seed_4_compositional_mt_systematicity_s_conj_synthetic_systematicity_synthetic_1_s1_s2_tiny/avg_attn_mat_16_(15,_82)_tiny_s_conj_s1_s2_synthetic.pt\n",
      "Using saved avg matrix at /checkpoint/itayitzhak/attn_weigths/not_permuted_seed_4_compositional_mt_systematicity_s_conj_synthetic_systematicity_synthetic_1_s1_s2_tiny/avg_attn_mat_16_(15,_82)_tiny_s_conj_s1_s2_synthetic.pt\n",
      "Percentage of EOS focused heads:  0.00% | Percentage of self focused heads: 0.00% | Percentage of Local focused heads: 0.00%\n",
      "Trying to load: /checkpoint/itayitzhak/attn_weigths/not_permuted_seed_4_compositional_mt_systematicity_s_conj_synthetic_systematicity_synthetic_1_s1_s2_tiny/avg_attn_mat_17_(83,_201)_tiny_s_conj_s1_s2_synthetic.pt\n",
      "Using saved avg matrix at /checkpoint/itayitzhak/attn_weigths/not_permuted_seed_4_compositional_mt_systematicity_s_conj_synthetic_systematicity_synthetic_1_s1_s2_tiny/avg_attn_mat_17_(83,_201)_tiny_s_conj_s1_s2_synthetic.pt\n",
      "Percentage of EOS focused heads:  0.00% | Percentage of self focused heads: 0.00% | Percentage of Local focused heads: 0.00%\n",
      "Trying to load: /checkpoint/itayitzhak/attn_weigths/not_permuted_seed_4_compositional_mt_systematicity_s_conj_synthetic_systematicity_synthetic_1_s1_s2_tiny/avg_attn_mat_18_(202,_347)_tiny_s_conj_s1_s2_synthetic.pt\n",
      "Using saved avg matrix at /checkpoint/itayitzhak/attn_weigths/not_permuted_seed_4_compositional_mt_systematicity_s_conj_synthetic_systematicity_synthetic_1_s1_s2_tiny/avg_attn_mat_18_(202,_347)_tiny_s_conj_s1_s2_synthetic.pt\n",
      "Percentage of EOS focused heads:  0.00% | Percentage of self focused heads: 0.00% | Percentage of Local focused heads: 0.00%\n",
      "Trying to load: /checkpoint/itayitzhak/attn_weigths/not_permuted_seed_4_compositional_mt_systematicity_s_conj_synthetic_systematicity_synthetic_1_s1_s2_tiny/avg_attn_mat_19_(348,_432)_tiny_s_conj_s1_s2_synthetic.pt\n",
      "Using saved avg matrix at /checkpoint/itayitzhak/attn_weigths/not_permuted_seed_4_compositional_mt_systematicity_s_conj_synthetic_systematicity_synthetic_1_s1_s2_tiny/avg_attn_mat_19_(348,_432)_tiny_s_conj_s1_s2_synthetic.pt\n",
      "Percentage of EOS focused heads:  0.00% | Percentage of self focused heads: 0.00% | Percentage of Local focused heads: 0.00%\n",
      "Trying to load: /checkpoint/itayitzhak/attn_weigths/not_permuted_seed_4_compositional_mt_systematicity_s_conj_synthetic_systematicity_synthetic_1_s1_s2_tiny/avg_attn_mat_20_(433,_476)_tiny_s_conj_s1_s2_synthetic.pt\n",
      "Using saved avg matrix at /checkpoint/itayitzhak/attn_weigths/not_permuted_seed_4_compositional_mt_systematicity_s_conj_synthetic_systematicity_synthetic_1_s1_s2_tiny/avg_attn_mat_20_(433,_476)_tiny_s_conj_s1_s2_synthetic.pt\n",
      "Percentage of EOS focused heads:  0.00% | Percentage of self focused heads: 0.00% | Percentage of Local focused heads: 0.00%\n",
      "Trying to load: /checkpoint/itayitzhak/attn_weigths/not_permuted_seed_4_compositional_mt_systematicity_s_conj_synthetic_systematicity_synthetic_1_s1_s2_tiny/avg_attn_mat_21_(477,_493)_tiny_s_conj_s1_s2_synthetic.pt\n",
      "Using saved avg matrix at /checkpoint/itayitzhak/attn_weigths/not_permuted_seed_4_compositional_mt_systematicity_s_conj_synthetic_systematicity_synthetic_1_s1_s2_tiny/avg_attn_mat_21_(477,_493)_tiny_s_conj_s1_s2_synthetic.pt\n",
      "Percentage of EOS focused heads:  0.00% | Percentage of self focused heads: 0.00% | Percentage of Local focused heads: 0.00%\n",
      "Trying to load: /checkpoint/itayitzhak/attn_weigths/not_permuted_seed_4_compositional_mt_systematicity_s_conj_synthetic_systematicity_synthetic_1_s1_s2_tiny/avg_attn_mat_22_(494,_498)_tiny_s_conj_s1_s2_synthetic.pt\n",
      "Using saved avg matrix at /checkpoint/itayitzhak/attn_weigths/not_permuted_seed_4_compositional_mt_systematicity_s_conj_synthetic_systematicity_synthetic_1_s1_s2_tiny/avg_attn_mat_22_(494,_498)_tiny_s_conj_s1_s2_synthetic.pt\n",
      "Percentage of EOS focused heads:  0.00% | Percentage of self focused heads: 0.00% | Percentage of Local focused heads: 0.00%\n",
      "Trying to load: /checkpoint/itayitzhak/attn_weigths/not_permuted_seed_4_compositional_mt_systematicity_s_conj_synthetic_systematicity_synthetic_1_s1_s2_tiny/avg_attn_mat_23_(499,_499)_tiny_s_conj_s1_s2_synthetic.pt\n",
      "Using saved avg matrix at /checkpoint/itayitzhak/attn_weigths/not_permuted_seed_4_compositional_mt_systematicity_s_conj_synthetic_systematicity_synthetic_1_s1_s2_tiny/avg_attn_mat_23_(499,_499)_tiny_s_conj_s1_s2_synthetic.pt\n",
      "Percentage of EOS focused heads:  0.00% | Percentage of self focused heads: 0.00% | Percentage of Local focused heads: 0.00%\n",
      "====================================================================================================\n",
      "Model 1/9\n",
      "====================================================================================================\n",
      "getting samples dict from: /checkpoint/itayitzhak/attn_weigths/remove_eos_not_permuted_seed_4_compositional_mt_systematicity_s_conj_synthetic_systematicity_synthetic_1_s1_s2_tiny/generate-test.txt\n",
      "Loading lengths_dict from: /checkpoint/itayitzhak/attn_weigths/remove_eos_not_permuted_seed_4_compositional_mt_systematicity_s_conj_synthetic_systematicity_synthetic_1_s1_s2_tiny\n",
      "lengths_dict:{14: 15, 15: 68, 16: 119, 17: 146, 18: 85, 19: 44, 20: 17, 21: 5, 22: 1}\n",
      "Trying to load: /checkpoint/itayitzhak/attn_weigths/remove_eos_not_permuted_seed_4_compositional_mt_systematicity_s_conj_synthetic_systematicity_synthetic_1_s1_s2_tiny/avg_attn_mat_14_(0,_14)_tiny_s_conj_s1_s2_synthetic.pt\n",
      "Using saved avg matrix at /checkpoint/itayitzhak/attn_weigths/remove_eos_not_permuted_seed_4_compositional_mt_systematicity_s_conj_synthetic_systematicity_synthetic_1_s1_s2_tiny/avg_attn_mat_14_(0,_14)_tiny_s_conj_s1_s2_synthetic.pt\n",
      "Percentage of EOS focused heads:  0.00% | Percentage of self focused heads: 0.00% | Percentage of Local focused heads: 0.00%\n",
      "Trying to load: /checkpoint/itayitzhak/attn_weigths/remove_eos_not_permuted_seed_4_compositional_mt_systematicity_s_conj_synthetic_systematicity_synthetic_1_s1_s2_tiny/avg_attn_mat_15_(15,_82)_tiny_s_conj_s1_s2_synthetic.pt\n",
      "Using saved avg matrix at /checkpoint/itayitzhak/attn_weigths/remove_eos_not_permuted_seed_4_compositional_mt_systematicity_s_conj_synthetic_systematicity_synthetic_1_s1_s2_tiny/avg_attn_mat_15_(15,_82)_tiny_s_conj_s1_s2_synthetic.pt\n",
      "Percentage of EOS focused heads:  0.00% | Percentage of self focused heads: 0.00% | Percentage of Local focused heads: 0.00%\n",
      "Trying to load: /checkpoint/itayitzhak/attn_weigths/remove_eos_not_permuted_seed_4_compositional_mt_systematicity_s_conj_synthetic_systematicity_synthetic_1_s1_s2_tiny/avg_attn_mat_16_(83,_201)_tiny_s_conj_s1_s2_synthetic.pt\n",
      "Using saved avg matrix at /checkpoint/itayitzhak/attn_weigths/remove_eos_not_permuted_seed_4_compositional_mt_systematicity_s_conj_synthetic_systematicity_synthetic_1_s1_s2_tiny/avg_attn_mat_16_(83,_201)_tiny_s_conj_s1_s2_synthetic.pt\n",
      "Percentage of EOS focused heads:  0.00% | Percentage of self focused heads: 0.00% | Percentage of Local focused heads: 0.00%\n",
      "Trying to load: /checkpoint/itayitzhak/attn_weigths/remove_eos_not_permuted_seed_4_compositional_mt_systematicity_s_conj_synthetic_systematicity_synthetic_1_s1_s2_tiny/avg_attn_mat_17_(202,_347)_tiny_s_conj_s1_s2_synthetic.pt\n",
      "Using saved avg matrix at /checkpoint/itayitzhak/attn_weigths/remove_eos_not_permuted_seed_4_compositional_mt_systematicity_s_conj_synthetic_systematicity_synthetic_1_s1_s2_tiny/avg_attn_mat_17_(202,_347)_tiny_s_conj_s1_s2_synthetic.pt\n",
      "Percentage of EOS focused heads:  0.00% | Percentage of self focused heads: 0.00% | Percentage of Local focused heads: 0.00%\n",
      "Trying to load: /checkpoint/itayitzhak/attn_weigths/remove_eos_not_permuted_seed_4_compositional_mt_systematicity_s_conj_synthetic_systematicity_synthetic_1_s1_s2_tiny/avg_attn_mat_18_(348,_432)_tiny_s_conj_s1_s2_synthetic.pt\n",
      "Using saved avg matrix at /checkpoint/itayitzhak/attn_weigths/remove_eos_not_permuted_seed_4_compositional_mt_systematicity_s_conj_synthetic_systematicity_synthetic_1_s1_s2_tiny/avg_attn_mat_18_(348,_432)_tiny_s_conj_s1_s2_synthetic.pt\n",
      "Percentage of EOS focused heads:  0.00% | Percentage of self focused heads: 0.00% | Percentage of Local focused heads: 0.00%\n",
      "Trying to load: /checkpoint/itayitzhak/attn_weigths/remove_eos_not_permuted_seed_4_compositional_mt_systematicity_s_conj_synthetic_systematicity_synthetic_1_s1_s2_tiny/avg_attn_mat_19_(433,_476)_tiny_s_conj_s1_s2_synthetic.pt\n",
      "Using saved avg matrix at /checkpoint/itayitzhak/attn_weigths/remove_eos_not_permuted_seed_4_compositional_mt_systematicity_s_conj_synthetic_systematicity_synthetic_1_s1_s2_tiny/avg_attn_mat_19_(433,_476)_tiny_s_conj_s1_s2_synthetic.pt\n",
      "Percentage of EOS focused heads:  0.00% | Percentage of self focused heads: 0.00% | Percentage of Local focused heads: 0.00%\n",
      "Trying to load: /checkpoint/itayitzhak/attn_weigths/remove_eos_not_permuted_seed_4_compositional_mt_systematicity_s_conj_synthetic_systematicity_synthetic_1_s1_s2_tiny/avg_attn_mat_20_(477,_493)_tiny_s_conj_s1_s2_synthetic.pt\n",
      "Using saved avg matrix at /checkpoint/itayitzhak/attn_weigths/remove_eos_not_permuted_seed_4_compositional_mt_systematicity_s_conj_synthetic_systematicity_synthetic_1_s1_s2_tiny/avg_attn_mat_20_(477,_493)_tiny_s_conj_s1_s2_synthetic.pt\n",
      "Percentage of EOS focused heads:  0.00% | Percentage of self focused heads: 0.00% | Percentage of Local focused heads: 0.00%\n",
      "Trying to load: /checkpoint/itayitzhak/attn_weigths/remove_eos_not_permuted_seed_4_compositional_mt_systematicity_s_conj_synthetic_systematicity_synthetic_1_s1_s2_tiny/avg_attn_mat_21_(494,_498)_tiny_s_conj_s1_s2_synthetic.pt\n",
      "Using saved avg matrix at /checkpoint/itayitzhak/attn_weigths/remove_eos_not_permuted_seed_4_compositional_mt_systematicity_s_conj_synthetic_systematicity_synthetic_1_s1_s2_tiny/avg_attn_mat_21_(494,_498)_tiny_s_conj_s1_s2_synthetic.pt\n",
      "Percentage of EOS focused heads:  0.00% | Percentage of self focused heads: 0.00% | Percentage of Local focused heads: 0.00%\n",
      "Trying to load: /checkpoint/itayitzhak/attn_weigths/remove_eos_not_permuted_seed_4_compositional_mt_systematicity_s_conj_synthetic_systematicity_synthetic_1_s1_s2_tiny/avg_attn_mat_22_(499,_499)_tiny_s_conj_s1_s2_synthetic.pt\n",
      "Using saved avg matrix at /checkpoint/itayitzhak/attn_weigths/remove_eos_not_permuted_seed_4_compositional_mt_systematicity_s_conj_synthetic_systematicity_synthetic_1_s1_s2_tiny/avg_attn_mat_22_(499,_499)_tiny_s_conj_s1_s2_synthetic.pt\n",
      "Percentage of EOS focused heads:  0.00% | Percentage of self focused heads: 0.00% | Percentage of Local focused heads: 0.00%\n",
      "====================================================================================================\n",
      "Model 2/9\n",
      "====================================================================================================\n",
      "getting samples dict from: /checkpoint/itayitzhak/attn_weigths/not_permuted_seed_4_compositional_mt_systematicity_s_conj_synthetic_systematicity_synthetic_1_s1_s2_tiny/generate-test.txt\n",
      "Loading lengths_dict from: /checkpoint/itayitzhak/attn_weigths/not_permuted_seed_4_compositional_mt_systematicity_s_conj_synthetic_systematicity_synthetic_1_s1_s2_tiny\n",
      "lengths_dict:{15: 15, 16: 68, 17: 119, 18: 146, 19: 85, 20: 44, 21: 17, 22: 5, 23: 1}\n",
      "Trying to load: /checkpoint/itayitzhak/attn_weigths/not_permuted_seed_4_compositional_mt_systematicity_s_conj_synthetic_systematicity_synthetic_1_s1_s2_tiny/avg_attn_mat_15_(0,_14)_tiny_s_conj_s1_s2_synthetic.pt\n",
      "Using saved avg matrix at /checkpoint/itayitzhak/attn_weigths/not_permuted_seed_4_compositional_mt_systematicity_s_conj_synthetic_systematicity_synthetic_1_s1_s2_tiny/avg_attn_mat_15_(0,_14)_tiny_s_conj_s1_s2_synthetic.pt\n",
      "Percentage of EOS focused heads:  0.00% | Percentage of self focused heads: 0.00% | Percentage of Local focused heads: 0.00%\n",
      "Trying to load: /checkpoint/itayitzhak/attn_weigths/not_permuted_seed_4_compositional_mt_systematicity_s_conj_synthetic_systematicity_synthetic_1_s1_s2_tiny/avg_attn_mat_16_(15,_82)_tiny_s_conj_s1_s2_synthetic.pt\n",
      "Using saved avg matrix at /checkpoint/itayitzhak/attn_weigths/not_permuted_seed_4_compositional_mt_systematicity_s_conj_synthetic_systematicity_synthetic_1_s1_s2_tiny/avg_attn_mat_16_(15,_82)_tiny_s_conj_s1_s2_synthetic.pt\n",
      "Percentage of EOS focused heads:  0.00% | Percentage of self focused heads: 0.00% | Percentage of Local focused heads: 0.00%\n",
      "Trying to load: /checkpoint/itayitzhak/attn_weigths/not_permuted_seed_4_compositional_mt_systematicity_s_conj_synthetic_systematicity_synthetic_1_s1_s2_tiny/avg_attn_mat_17_(83,_201)_tiny_s_conj_s1_s2_synthetic.pt\n",
      "Using saved avg matrix at /checkpoint/itayitzhak/attn_weigths/not_permuted_seed_4_compositional_mt_systematicity_s_conj_synthetic_systematicity_synthetic_1_s1_s2_tiny/avg_attn_mat_17_(83,_201)_tiny_s_conj_s1_s2_synthetic.pt\n",
      "Percentage of EOS focused heads:  0.00% | Percentage of self focused heads: 0.00% | Percentage of Local focused heads: 0.00%\n",
      "Trying to load: /checkpoint/itayitzhak/attn_weigths/not_permuted_seed_4_compositional_mt_systematicity_s_conj_synthetic_systematicity_synthetic_1_s1_s2_tiny/avg_attn_mat_18_(202,_347)_tiny_s_conj_s1_s2_synthetic.pt\n",
      "Using saved avg matrix at /checkpoint/itayitzhak/attn_weigths/not_permuted_seed_4_compositional_mt_systematicity_s_conj_synthetic_systematicity_synthetic_1_s1_s2_tiny/avg_attn_mat_18_(202,_347)_tiny_s_conj_s1_s2_synthetic.pt\n",
      "Percentage of EOS focused heads:  0.00% | Percentage of self focused heads: 0.00% | Percentage of Local focused heads: 0.00%\n",
      "Trying to load: /checkpoint/itayitzhak/attn_weigths/not_permuted_seed_4_compositional_mt_systematicity_s_conj_synthetic_systematicity_synthetic_1_s1_s2_tiny/avg_attn_mat_19_(348,_432)_tiny_s_conj_s1_s2_synthetic.pt\n",
      "Using saved avg matrix at /checkpoint/itayitzhak/attn_weigths/not_permuted_seed_4_compositional_mt_systematicity_s_conj_synthetic_systematicity_synthetic_1_s1_s2_tiny/avg_attn_mat_19_(348,_432)_tiny_s_conj_s1_s2_synthetic.pt\n",
      "Percentage of EOS focused heads:  0.00% | Percentage of self focused heads: 0.00% | Percentage of Local focused heads: 0.00%\n",
      "Trying to load: /checkpoint/itayitzhak/attn_weigths/not_permuted_seed_4_compositional_mt_systematicity_s_conj_synthetic_systematicity_synthetic_1_s1_s2_tiny/avg_attn_mat_20_(433,_476)_tiny_s_conj_s1_s2_synthetic.pt\n",
      "Using saved avg matrix at /checkpoint/itayitzhak/attn_weigths/not_permuted_seed_4_compositional_mt_systematicity_s_conj_synthetic_systematicity_synthetic_1_s1_s2_tiny/avg_attn_mat_20_(433,_476)_tiny_s_conj_s1_s2_synthetic.pt\n",
      "Percentage of EOS focused heads:  0.00% | Percentage of self focused heads: 0.00% | Percentage of Local focused heads: 0.00%\n",
      "Trying to load: /checkpoint/itayitzhak/attn_weigths/not_permuted_seed_4_compositional_mt_systematicity_s_conj_synthetic_systematicity_synthetic_1_s1_s2_tiny/avg_attn_mat_21_(477,_493)_tiny_s_conj_s1_s2_synthetic.pt\n",
      "Using saved avg matrix at /checkpoint/itayitzhak/attn_weigths/not_permuted_seed_4_compositional_mt_systematicity_s_conj_synthetic_systematicity_synthetic_1_s1_s2_tiny/avg_attn_mat_21_(477,_493)_tiny_s_conj_s1_s2_synthetic.pt\n",
      "Percentage of EOS focused heads:  0.00% | Percentage of self focused heads: 0.00% | Percentage of Local focused heads: 0.00%\n",
      "Trying to load: /checkpoint/itayitzhak/attn_weigths/not_permuted_seed_4_compositional_mt_systematicity_s_conj_synthetic_systematicity_synthetic_1_s1_s2_tiny/avg_attn_mat_22_(494,_498)_tiny_s_conj_s1_s2_synthetic.pt\n",
      "Using saved avg matrix at /checkpoint/itayitzhak/attn_weigths/not_permuted_seed_4_compositional_mt_systematicity_s_conj_synthetic_systematicity_synthetic_1_s1_s2_tiny/avg_attn_mat_22_(494,_498)_tiny_s_conj_s1_s2_synthetic.pt\n",
      "Percentage of EOS focused heads:  0.00% | Percentage of self focused heads: 0.00% | Percentage of Local focused heads: 0.00%\n",
      "Trying to load: /checkpoint/itayitzhak/attn_weigths/not_permuted_seed_4_compositional_mt_systematicity_s_conj_synthetic_systematicity_synthetic_1_s1_s2_tiny/avg_attn_mat_23_(499,_499)_tiny_s_conj_s1_s2_synthetic.pt\n",
      "Using saved avg matrix at /checkpoint/itayitzhak/attn_weigths/not_permuted_seed_4_compositional_mt_systematicity_s_conj_synthetic_systematicity_synthetic_1_s1_s2_tiny/avg_attn_mat_23_(499,_499)_tiny_s_conj_s1_s2_synthetic.pt\n",
      "Percentage of EOS focused heads:  0.00% | Percentage of self focused heads: 0.00% | Percentage of Local focused heads: 0.00%\n",
      "====================================================================================================\n",
      "Model 3/9\n",
      "====================================================================================================\n",
      "getting samples dict from: /checkpoint/itayitzhak/attn_weigths/not_permuted_seed_4_compositional_mt_systematicity_s_conj_synthetic_systematicity_synthetic_1_s1_s2_small/generate-test.txt\n",
      "Loading lengths_dict from: /checkpoint/itayitzhak/attn_weigths/not_permuted_seed_4_compositional_mt_systematicity_s_conj_synthetic_systematicity_synthetic_1_s1_s2_small\n",
      "lengths_dict:{15: 15, 16: 68, 17: 119, 18: 146, 19: 85, 20: 44, 21: 17, 22: 5, 23: 1}\n",
      "Trying to load: /checkpoint/itayitzhak/attn_weigths/not_permuted_seed_4_compositional_mt_systematicity_s_conj_synthetic_systematicity_synthetic_1_s1_s2_small/avg_attn_mat_15_(0,_14)_small_s_conj_s1_s2_synthetic.pt\n",
      "Using saved avg matrix at /checkpoint/itayitzhak/attn_weigths/not_permuted_seed_4_compositional_mt_systematicity_s_conj_synthetic_systematicity_synthetic_1_s1_s2_small/avg_attn_mat_15_(0,_14)_small_s_conj_s1_s2_synthetic.pt\n",
      "Percentage of EOS focused heads:  11.11% | Percentage of self focused heads: 2.78% | Percentage of Local focused heads: 2.78%\n",
      "Trying to load: /checkpoint/itayitzhak/attn_weigths/not_permuted_seed_4_compositional_mt_systematicity_s_conj_synthetic_systematicity_synthetic_1_s1_s2_small/avg_attn_mat_16_(15,_82)_small_s_conj_s1_s2_synthetic.pt\n",
      "Using saved avg matrix at /checkpoint/itayitzhak/attn_weigths/not_permuted_seed_4_compositional_mt_systematicity_s_conj_synthetic_systematicity_synthetic_1_s1_s2_small/avg_attn_mat_16_(15,_82)_small_s_conj_s1_s2_synthetic.pt\n",
      "Percentage of EOS focused heads:  13.89% | Percentage of self focused heads: 2.78% | Percentage of Local focused heads: 2.78%\n",
      "Trying to load: /checkpoint/itayitzhak/attn_weigths/not_permuted_seed_4_compositional_mt_systematicity_s_conj_synthetic_systematicity_synthetic_1_s1_s2_small/avg_attn_mat_17_(83,_201)_small_s_conj_s1_s2_synthetic.pt\n",
      "Using saved avg matrix at /checkpoint/itayitzhak/attn_weigths/not_permuted_seed_4_compositional_mt_systematicity_s_conj_synthetic_systematicity_synthetic_1_s1_s2_small/avg_attn_mat_17_(83,_201)_small_s_conj_s1_s2_synthetic.pt\n",
      "Percentage of EOS focused heads:  11.11% | Percentage of self focused heads: 2.78% | Percentage of Local focused heads: 2.78%\n",
      "Trying to load: /checkpoint/itayitzhak/attn_weigths/not_permuted_seed_4_compositional_mt_systematicity_s_conj_synthetic_systematicity_synthetic_1_s1_s2_small/avg_attn_mat_18_(202,_347)_small_s_conj_s1_s2_synthetic.pt\n",
      "Using saved avg matrix at /checkpoint/itayitzhak/attn_weigths/not_permuted_seed_4_compositional_mt_systematicity_s_conj_synthetic_systematicity_synthetic_1_s1_s2_small/avg_attn_mat_18_(202,_347)_small_s_conj_s1_s2_synthetic.pt\n",
      "Percentage of EOS focused heads:  13.89% | Percentage of self focused heads: 2.78% | Percentage of Local focused heads: 2.78%\n",
      "Trying to load: /checkpoint/itayitzhak/attn_weigths/not_permuted_seed_4_compositional_mt_systematicity_s_conj_synthetic_systematicity_synthetic_1_s1_s2_small/avg_attn_mat_19_(348,_432)_small_s_conj_s1_s2_synthetic.pt\n",
      "Using saved avg matrix at /checkpoint/itayitzhak/attn_weigths/not_permuted_seed_4_compositional_mt_systematicity_s_conj_synthetic_systematicity_synthetic_1_s1_s2_small/avg_attn_mat_19_(348,_432)_small_s_conj_s1_s2_synthetic.pt\n",
      "Percentage of EOS focused heads:  13.89% | Percentage of self focused heads: 2.78% | Percentage of Local focused heads: 2.78%\n",
      "Trying to load: /checkpoint/itayitzhak/attn_weigths/not_permuted_seed_4_compositional_mt_systematicity_s_conj_synthetic_systematicity_synthetic_1_s1_s2_small/avg_attn_mat_20_(433,_476)_small_s_conj_s1_s2_synthetic.pt\n",
      "Using saved avg matrix at /checkpoint/itayitzhak/attn_weigths/not_permuted_seed_4_compositional_mt_systematicity_s_conj_synthetic_systematicity_synthetic_1_s1_s2_small/avg_attn_mat_20_(433,_476)_small_s_conj_s1_s2_synthetic.pt\n",
      "Percentage of EOS focused heads:  5.56% | Percentage of self focused heads: 2.78% | Percentage of Local focused heads: 2.78%\n",
      "Trying to load: /checkpoint/itayitzhak/attn_weigths/not_permuted_seed_4_compositional_mt_systematicity_s_conj_synthetic_systematicity_synthetic_1_s1_s2_small/avg_attn_mat_21_(477,_493)_small_s_conj_s1_s2_synthetic.pt\n",
      "Using saved avg matrix at /checkpoint/itayitzhak/attn_weigths/not_permuted_seed_4_compositional_mt_systematicity_s_conj_synthetic_systematicity_synthetic_1_s1_s2_small/avg_attn_mat_21_(477,_493)_small_s_conj_s1_s2_synthetic.pt\n",
      "Percentage of EOS focused heads:  11.11% | Percentage of self focused heads: 5.56% | Percentage of Local focused heads: 5.56%\n",
      "Trying to load: /checkpoint/itayitzhak/attn_weigths/not_permuted_seed_4_compositional_mt_systematicity_s_conj_synthetic_systematicity_synthetic_1_s1_s2_small/avg_attn_mat_22_(494,_498)_small_s_conj_s1_s2_synthetic.pt\n",
      "Using saved avg matrix at /checkpoint/itayitzhak/attn_weigths/not_permuted_seed_4_compositional_mt_systematicity_s_conj_synthetic_systematicity_synthetic_1_s1_s2_small/avg_attn_mat_22_(494,_498)_small_s_conj_s1_s2_synthetic.pt\n",
      "Percentage of EOS focused heads:  5.56% | Percentage of self focused heads: 2.78% | Percentage of Local focused heads: 2.78%\n",
      "Trying to load: /checkpoint/itayitzhak/attn_weigths/not_permuted_seed_4_compositional_mt_systematicity_s_conj_synthetic_systematicity_synthetic_1_s1_s2_small/avg_attn_mat_23_(499,_499)_small_s_conj_s1_s2_synthetic.pt\n",
      "Using saved avg matrix at /checkpoint/itayitzhak/attn_weigths/not_permuted_seed_4_compositional_mt_systematicity_s_conj_synthetic_systematicity_synthetic_1_s1_s2_small/avg_attn_mat_23_(499,_499)_small_s_conj_s1_s2_synthetic.pt\n",
      "Percentage of EOS focused heads:  2.78% | Percentage of self focused heads: 2.78% | Percentage of Local focused heads: 2.78%\n",
      "====================================================================================================\n",
      "Model 4/9\n",
      "====================================================================================================\n",
      "getting samples dict from: /checkpoint/itayitzhak/attn_weigths/remove_eos_not_permuted_seed_4_compositional_mt_systematicity_s_conj_synthetic_systematicity_synthetic_1_s1_s2_small/generate-test.txt\n",
      "Loading lengths_dict from: /checkpoint/itayitzhak/attn_weigths/remove_eos_not_permuted_seed_4_compositional_mt_systematicity_s_conj_synthetic_systematicity_synthetic_1_s1_s2_small\n",
      "lengths_dict:{14: 15, 15: 68, 16: 119, 17: 146, 18: 85, 19: 44, 20: 17, 21: 5, 22: 1}\n",
      "Trying to load: /checkpoint/itayitzhak/attn_weigths/remove_eos_not_permuted_seed_4_compositional_mt_systematicity_s_conj_synthetic_systematicity_synthetic_1_s1_s2_small/avg_attn_mat_14_(0,_14)_small_s_conj_s1_s2_synthetic.pt\n",
      "Using saved avg matrix at /checkpoint/itayitzhak/attn_weigths/remove_eos_not_permuted_seed_4_compositional_mt_systematicity_s_conj_synthetic_systematicity_synthetic_1_s1_s2_small/avg_attn_mat_14_(0,_14)_small_s_conj_s1_s2_synthetic.pt\n",
      "Percentage of EOS focused heads:  0.00% | Percentage of self focused heads: 8.33% | Percentage of Local focused heads: 8.33%\n",
      "Trying to load: /checkpoint/itayitzhak/attn_weigths/remove_eos_not_permuted_seed_4_compositional_mt_systematicity_s_conj_synthetic_systematicity_synthetic_1_s1_s2_small/avg_attn_mat_15_(15,_82)_small_s_conj_s1_s2_synthetic.pt\n",
      "Using saved avg matrix at /checkpoint/itayitzhak/attn_weigths/remove_eos_not_permuted_seed_4_compositional_mt_systematicity_s_conj_synthetic_systematicity_synthetic_1_s1_s2_small/avg_attn_mat_15_(15,_82)_small_s_conj_s1_s2_synthetic.pt\n",
      "Percentage of EOS focused heads:  0.00% | Percentage of self focused heads: 11.11% | Percentage of Local focused heads: 11.11%\n",
      "Trying to load: /checkpoint/itayitzhak/attn_weigths/remove_eos_not_permuted_seed_4_compositional_mt_systematicity_s_conj_synthetic_systematicity_synthetic_1_s1_s2_small/avg_attn_mat_16_(83,_201)_small_s_conj_s1_s2_synthetic.pt\n",
      "Using saved avg matrix at /checkpoint/itayitzhak/attn_weigths/remove_eos_not_permuted_seed_4_compositional_mt_systematicity_s_conj_synthetic_systematicity_synthetic_1_s1_s2_small/avg_attn_mat_16_(83,_201)_small_s_conj_s1_s2_synthetic.pt\n",
      "Percentage of EOS focused heads:  0.00% | Percentage of self focused heads: 11.11% | Percentage of Local focused heads: 11.11%\n",
      "Trying to load: /checkpoint/itayitzhak/attn_weigths/remove_eos_not_permuted_seed_4_compositional_mt_systematicity_s_conj_synthetic_systematicity_synthetic_1_s1_s2_small/avg_attn_mat_17_(202,_347)_small_s_conj_s1_s2_synthetic.pt\n",
      "Using saved avg matrix at /checkpoint/itayitzhak/attn_weigths/remove_eos_not_permuted_seed_4_compositional_mt_systematicity_s_conj_synthetic_systematicity_synthetic_1_s1_s2_small/avg_attn_mat_17_(202,_347)_small_s_conj_s1_s2_synthetic.pt\n",
      "Percentage of EOS focused heads:  0.00% | Percentage of self focused heads: 11.11% | Percentage of Local focused heads: 11.11%\n",
      "Trying to load: /checkpoint/itayitzhak/attn_weigths/remove_eos_not_permuted_seed_4_compositional_mt_systematicity_s_conj_synthetic_systematicity_synthetic_1_s1_s2_small/avg_attn_mat_18_(348,_432)_small_s_conj_s1_s2_synthetic.pt\n",
      "Using saved avg matrix at /checkpoint/itayitzhak/attn_weigths/remove_eos_not_permuted_seed_4_compositional_mt_systematicity_s_conj_synthetic_systematicity_synthetic_1_s1_s2_small/avg_attn_mat_18_(348,_432)_small_s_conj_s1_s2_synthetic.pt\n",
      "Percentage of EOS focused heads:  0.00% | Percentage of self focused heads: 8.33% | Percentage of Local focused heads: 8.33%\n",
      "Trying to load: /checkpoint/itayitzhak/attn_weigths/remove_eos_not_permuted_seed_4_compositional_mt_systematicity_s_conj_synthetic_systematicity_synthetic_1_s1_s2_small/avg_attn_mat_19_(433,_476)_small_s_conj_s1_s2_synthetic.pt\n",
      "Using saved avg matrix at /checkpoint/itayitzhak/attn_weigths/remove_eos_not_permuted_seed_4_compositional_mt_systematicity_s_conj_synthetic_systematicity_synthetic_1_s1_s2_small/avg_attn_mat_19_(433,_476)_small_s_conj_s1_s2_synthetic.pt\n",
      "Percentage of EOS focused heads:  0.00% | Percentage of self focused heads: 5.56% | Percentage of Local focused heads: 5.56%\n",
      "Trying to load: /checkpoint/itayitzhak/attn_weigths/remove_eos_not_permuted_seed_4_compositional_mt_systematicity_s_conj_synthetic_systematicity_synthetic_1_s1_s2_small/avg_attn_mat_20_(477,_493)_small_s_conj_s1_s2_synthetic.pt\n",
      "Using saved avg matrix at /checkpoint/itayitzhak/attn_weigths/remove_eos_not_permuted_seed_4_compositional_mt_systematicity_s_conj_synthetic_systematicity_synthetic_1_s1_s2_small/avg_attn_mat_20_(477,_493)_small_s_conj_s1_s2_synthetic.pt\n",
      "Percentage of EOS focused heads:  0.00% | Percentage of self focused heads: 5.56% | Percentage of Local focused heads: 5.56%\n",
      "Trying to load: /checkpoint/itayitzhak/attn_weigths/remove_eos_not_permuted_seed_4_compositional_mt_systematicity_s_conj_synthetic_systematicity_synthetic_1_s1_s2_small/avg_attn_mat_21_(494,_498)_small_s_conj_s1_s2_synthetic.pt\n",
      "Using saved avg matrix at /checkpoint/itayitzhak/attn_weigths/remove_eos_not_permuted_seed_4_compositional_mt_systematicity_s_conj_synthetic_systematicity_synthetic_1_s1_s2_small/avg_attn_mat_21_(494,_498)_small_s_conj_s1_s2_synthetic.pt\n",
      "Percentage of EOS focused heads:  0.00% | Percentage of self focused heads: 5.56% | Percentage of Local focused heads: 5.56%\n",
      "Trying to load: /checkpoint/itayitzhak/attn_weigths/remove_eos_not_permuted_seed_4_compositional_mt_systematicity_s_conj_synthetic_systematicity_synthetic_1_s1_s2_small/avg_attn_mat_22_(499,_499)_small_s_conj_s1_s2_synthetic.pt\n",
      "Using saved avg matrix at /checkpoint/itayitzhak/attn_weigths/remove_eos_not_permuted_seed_4_compositional_mt_systematicity_s_conj_synthetic_systematicity_synthetic_1_s1_s2_small/avg_attn_mat_22_(499,_499)_small_s_conj_s1_s2_synthetic.pt\n",
      "Percentage of EOS focused heads:  0.00% | Percentage of self focused heads: 5.56% | Percentage of Local focused heads: 5.56%\n",
      "====================================================================================================\n",
      "Model 5/9\n",
      "====================================================================================================\n",
      "getting samples dict from: /checkpoint/itayitzhak/attn_weigths/not_permuted_seed_4_compositional_mt_systematicity_s_conj_synthetic_systematicity_synthetic_1_s1_s2_small/generate-test.txt\n",
      "Loading lengths_dict from: /checkpoint/itayitzhak/attn_weigths/not_permuted_seed_4_compositional_mt_systematicity_s_conj_synthetic_systematicity_synthetic_1_s1_s2_small\n",
      "lengths_dict:{15: 15, 16: 68, 17: 119, 18: 146, 19: 85, 20: 44, 21: 17, 22: 5, 23: 1}\n",
      "Trying to load: /checkpoint/itayitzhak/attn_weigths/not_permuted_seed_4_compositional_mt_systematicity_s_conj_synthetic_systematicity_synthetic_1_s1_s2_small/avg_attn_mat_15_(0,_14)_small_s_conj_s1_s2_synthetic.pt\n",
      "Using saved avg matrix at /checkpoint/itayitzhak/attn_weigths/not_permuted_seed_4_compositional_mt_systematicity_s_conj_synthetic_systematicity_synthetic_1_s1_s2_small/avg_attn_mat_15_(0,_14)_small_s_conj_s1_s2_synthetic.pt\n",
      "Percentage of EOS focused heads:  0.00% | Percentage of self focused heads: 2.78% | Percentage of Local focused heads: 2.78%\n",
      "Trying to load: /checkpoint/itayitzhak/attn_weigths/not_permuted_seed_4_compositional_mt_systematicity_s_conj_synthetic_systematicity_synthetic_1_s1_s2_small/avg_attn_mat_16_(15,_82)_small_s_conj_s1_s2_synthetic.pt\n",
      "Using saved avg matrix at /checkpoint/itayitzhak/attn_weigths/not_permuted_seed_4_compositional_mt_systematicity_s_conj_synthetic_systematicity_synthetic_1_s1_s2_small/avg_attn_mat_16_(15,_82)_small_s_conj_s1_s2_synthetic.pt\n",
      "Percentage of EOS focused heads:  0.00% | Percentage of self focused heads: 2.78% | Percentage of Local focused heads: 2.78%\n",
      "Trying to load: /checkpoint/itayitzhak/attn_weigths/not_permuted_seed_4_compositional_mt_systematicity_s_conj_synthetic_systematicity_synthetic_1_s1_s2_small/avg_attn_mat_17_(83,_201)_small_s_conj_s1_s2_synthetic.pt\n",
      "Using saved avg matrix at /checkpoint/itayitzhak/attn_weigths/not_permuted_seed_4_compositional_mt_systematicity_s_conj_synthetic_systematicity_synthetic_1_s1_s2_small/avg_attn_mat_17_(83,_201)_small_s_conj_s1_s2_synthetic.pt\n",
      "Percentage of EOS focused heads:  0.00% | Percentage of self focused heads: 2.78% | Percentage of Local focused heads: 2.78%\n",
      "Trying to load: /checkpoint/itayitzhak/attn_weigths/not_permuted_seed_4_compositional_mt_systematicity_s_conj_synthetic_systematicity_synthetic_1_s1_s2_small/avg_attn_mat_18_(202,_347)_small_s_conj_s1_s2_synthetic.pt\n",
      "Using saved avg matrix at /checkpoint/itayitzhak/attn_weigths/not_permuted_seed_4_compositional_mt_systematicity_s_conj_synthetic_systematicity_synthetic_1_s1_s2_small/avg_attn_mat_18_(202,_347)_small_s_conj_s1_s2_synthetic.pt\n",
      "Percentage of EOS focused heads:  0.00% | Percentage of self focused heads: 2.78% | Percentage of Local focused heads: 2.78%\n",
      "Trying to load: /checkpoint/itayitzhak/attn_weigths/not_permuted_seed_4_compositional_mt_systematicity_s_conj_synthetic_systematicity_synthetic_1_s1_s2_small/avg_attn_mat_19_(348,_432)_small_s_conj_s1_s2_synthetic.pt\n",
      "Using saved avg matrix at /checkpoint/itayitzhak/attn_weigths/not_permuted_seed_4_compositional_mt_systematicity_s_conj_synthetic_systematicity_synthetic_1_s1_s2_small/avg_attn_mat_19_(348,_432)_small_s_conj_s1_s2_synthetic.pt\n",
      "Percentage of EOS focused heads:  0.00% | Percentage of self focused heads: 2.78% | Percentage of Local focused heads: 2.78%\n",
      "Trying to load: /checkpoint/itayitzhak/attn_weigths/not_permuted_seed_4_compositional_mt_systematicity_s_conj_synthetic_systematicity_synthetic_1_s1_s2_small/avg_attn_mat_20_(433,_476)_small_s_conj_s1_s2_synthetic.pt\n",
      "Using saved avg matrix at /checkpoint/itayitzhak/attn_weigths/not_permuted_seed_4_compositional_mt_systematicity_s_conj_synthetic_systematicity_synthetic_1_s1_s2_small/avg_attn_mat_20_(433,_476)_small_s_conj_s1_s2_synthetic.pt\n",
      "Percentage of EOS focused heads:  0.00% | Percentage of self focused heads: 2.78% | Percentage of Local focused heads: 2.78%\n",
      "Trying to load: /checkpoint/itayitzhak/attn_weigths/not_permuted_seed_4_compositional_mt_systematicity_s_conj_synthetic_systematicity_synthetic_1_s1_s2_small/avg_attn_mat_21_(477,_493)_small_s_conj_s1_s2_synthetic.pt\n",
      "Using saved avg matrix at /checkpoint/itayitzhak/attn_weigths/not_permuted_seed_4_compositional_mt_systematicity_s_conj_synthetic_systematicity_synthetic_1_s1_s2_small/avg_attn_mat_21_(477,_493)_small_s_conj_s1_s2_synthetic.pt\n",
      "Percentage of EOS focused heads:  0.00% | Percentage of self focused heads: 2.78% | Percentage of Local focused heads: 2.78%\n",
      "Trying to load: /checkpoint/itayitzhak/attn_weigths/not_permuted_seed_4_compositional_mt_systematicity_s_conj_synthetic_systematicity_synthetic_1_s1_s2_small/avg_attn_mat_22_(494,_498)_small_s_conj_s1_s2_synthetic.pt\n",
      "Using saved avg matrix at /checkpoint/itayitzhak/attn_weigths/not_permuted_seed_4_compositional_mt_systematicity_s_conj_synthetic_systematicity_synthetic_1_s1_s2_small/avg_attn_mat_22_(494,_498)_small_s_conj_s1_s2_synthetic.pt\n",
      "Percentage of EOS focused heads:  0.00% | Percentage of self focused heads: 2.78% | Percentage of Local focused heads: 2.78%\n",
      "Trying to load: /checkpoint/itayitzhak/attn_weigths/not_permuted_seed_4_compositional_mt_systematicity_s_conj_synthetic_systematicity_synthetic_1_s1_s2_small/avg_attn_mat_23_(499,_499)_small_s_conj_s1_s2_synthetic.pt\n",
      "Using saved avg matrix at /checkpoint/itayitzhak/attn_weigths/not_permuted_seed_4_compositional_mt_systematicity_s_conj_synthetic_systematicity_synthetic_1_s1_s2_small/avg_attn_mat_23_(499,_499)_small_s_conj_s1_s2_synthetic.pt\n",
      "Percentage of EOS focused heads:  0.00% | Percentage of self focused heads: 2.78% | Percentage of Local focused heads: 2.78%\n",
      "====================================================================================================\n",
      "Model 6/9\n",
      "====================================================================================================\n",
      "getting samples dict from: /checkpoint/itayitzhak/attn_weigths/not_permuted_seed_4_compositional_mt_systematicity_s_conj_synthetic_systematicity_synthetic_1_s1_s2_all/generate-test.txt\n",
      "Loading lengths_dict from: /checkpoint/itayitzhak/attn_weigths/not_permuted_seed_4_compositional_mt_systematicity_s_conj_synthetic_systematicity_synthetic_1_s1_s2_all\n",
      "lengths_dict:{15: 15, 16: 68, 17: 119, 18: 146, 19: 85, 20: 44, 21: 17, 22: 5, 23: 1}\n",
      "Trying to load: /checkpoint/itayitzhak/attn_weigths/not_permuted_seed_4_compositional_mt_systematicity_s_conj_synthetic_systematicity_synthetic_1_s1_s2_all/avg_attn_mat_15_(0,_14)_all_s_conj_s1_s2_synthetic.pt\n",
      "Using saved avg matrix at /checkpoint/itayitzhak/attn_weigths/not_permuted_seed_4_compositional_mt_systematicity_s_conj_synthetic_systematicity_synthetic_1_s1_s2_all/avg_attn_mat_15_(0,_14)_all_s_conj_s1_s2_synthetic.pt\n",
      "Percentage of EOS focused heads:  22.22% | Percentage of self focused heads: 16.67% | Percentage of Local focused heads: 16.67%\n",
      "Trying to load: /checkpoint/itayitzhak/attn_weigths/not_permuted_seed_4_compositional_mt_systematicity_s_conj_synthetic_systematicity_synthetic_1_s1_s2_all/avg_attn_mat_16_(15,_82)_all_s_conj_s1_s2_synthetic.pt\n",
      "Using saved avg matrix at /checkpoint/itayitzhak/attn_weigths/not_permuted_seed_4_compositional_mt_systematicity_s_conj_synthetic_systematicity_synthetic_1_s1_s2_all/avg_attn_mat_16_(15,_82)_all_s_conj_s1_s2_synthetic.pt\n",
      "Percentage of EOS focused heads:  25.00% | Percentage of self focused heads: 13.89% | Percentage of Local focused heads: 13.89%\n",
      "Trying to load: /checkpoint/itayitzhak/attn_weigths/not_permuted_seed_4_compositional_mt_systematicity_s_conj_synthetic_systematicity_synthetic_1_s1_s2_all/avg_attn_mat_17_(83,_201)_all_s_conj_s1_s2_synthetic.pt\n",
      "Using saved avg matrix at /checkpoint/itayitzhak/attn_weigths/not_permuted_seed_4_compositional_mt_systematicity_s_conj_synthetic_systematicity_synthetic_1_s1_s2_all/avg_attn_mat_17_(83,_201)_all_s_conj_s1_s2_synthetic.pt\n",
      "Percentage of EOS focused heads:  27.78% | Percentage of self focused heads: 13.89% | Percentage of Local focused heads: 13.89%\n",
      "Trying to load: /checkpoint/itayitzhak/attn_weigths/not_permuted_seed_4_compositional_mt_systematicity_s_conj_synthetic_systematicity_synthetic_1_s1_s2_all/avg_attn_mat_18_(202,_347)_all_s_conj_s1_s2_synthetic.pt\n",
      "Using saved avg matrix at /checkpoint/itayitzhak/attn_weigths/not_permuted_seed_4_compositional_mt_systematicity_s_conj_synthetic_systematicity_synthetic_1_s1_s2_all/avg_attn_mat_18_(202,_347)_all_s_conj_s1_s2_synthetic.pt\n",
      "Percentage of EOS focused heads:  30.56% | Percentage of self focused heads: 16.67% | Percentage of Local focused heads: 16.67%\n",
      "Trying to load: /checkpoint/itayitzhak/attn_weigths/not_permuted_seed_4_compositional_mt_systematicity_s_conj_synthetic_systematicity_synthetic_1_s1_s2_all/avg_attn_mat_19_(348,_432)_all_s_conj_s1_s2_synthetic.pt\n",
      "Using saved avg matrix at /checkpoint/itayitzhak/attn_weigths/not_permuted_seed_4_compositional_mt_systematicity_s_conj_synthetic_systematicity_synthetic_1_s1_s2_all/avg_attn_mat_19_(348,_432)_all_s_conj_s1_s2_synthetic.pt\n",
      "Percentage of EOS focused heads:  30.56% | Percentage of self focused heads: 13.89% | Percentage of Local focused heads: 13.89%\n",
      "Trying to load: /checkpoint/itayitzhak/attn_weigths/not_permuted_seed_4_compositional_mt_systematicity_s_conj_synthetic_systematicity_synthetic_1_s1_s2_all/avg_attn_mat_20_(433,_476)_all_s_conj_s1_s2_synthetic.pt\n",
      "Using saved avg matrix at /checkpoint/itayitzhak/attn_weigths/not_permuted_seed_4_compositional_mt_systematicity_s_conj_synthetic_systematicity_synthetic_1_s1_s2_all/avg_attn_mat_20_(433,_476)_all_s_conj_s1_s2_synthetic.pt\n",
      "Percentage of EOS focused heads:  25.00% | Percentage of self focused heads: 13.89% | Percentage of Local focused heads: 13.89%\n",
      "Trying to load: /checkpoint/itayitzhak/attn_weigths/not_permuted_seed_4_compositional_mt_systematicity_s_conj_synthetic_systematicity_synthetic_1_s1_s2_all/avg_attn_mat_21_(477,_493)_all_s_conj_s1_s2_synthetic.pt\n",
      "Using saved avg matrix at /checkpoint/itayitzhak/attn_weigths/not_permuted_seed_4_compositional_mt_systematicity_s_conj_synthetic_systematicity_synthetic_1_s1_s2_all/avg_attn_mat_21_(477,_493)_all_s_conj_s1_s2_synthetic.pt\n",
      "Percentage of EOS focused heads:  22.22% | Percentage of self focused heads: 19.44% | Percentage of Local focused heads: 19.44%\n",
      "Trying to load: /checkpoint/itayitzhak/attn_weigths/not_permuted_seed_4_compositional_mt_systematicity_s_conj_synthetic_systematicity_synthetic_1_s1_s2_all/avg_attn_mat_22_(494,_498)_all_s_conj_s1_s2_synthetic.pt\n",
      "Using saved avg matrix at /checkpoint/itayitzhak/attn_weigths/not_permuted_seed_4_compositional_mt_systematicity_s_conj_synthetic_systematicity_synthetic_1_s1_s2_all/avg_attn_mat_22_(494,_498)_all_s_conj_s1_s2_synthetic.pt\n",
      "Percentage of EOS focused heads:  13.89% | Percentage of self focused heads: 16.67% | Percentage of Local focused heads: 16.67%\n",
      "Trying to load: /checkpoint/itayitzhak/attn_weigths/not_permuted_seed_4_compositional_mt_systematicity_s_conj_synthetic_systematicity_synthetic_1_s1_s2_all/avg_attn_mat_23_(499,_499)_all_s_conj_s1_s2_synthetic.pt\n",
      "Using saved avg matrix at /checkpoint/itayitzhak/attn_weigths/not_permuted_seed_4_compositional_mt_systematicity_s_conj_synthetic_systematicity_synthetic_1_s1_s2_all/avg_attn_mat_23_(499,_499)_all_s_conj_s1_s2_synthetic.pt\n",
      "Percentage of EOS focused heads:  8.33% | Percentage of self focused heads: 13.89% | Percentage of Local focused heads: 13.89%\n",
      "====================================================================================================\n",
      "Model 7/9\n",
      "====================================================================================================\n",
      "getting samples dict from: /checkpoint/itayitzhak/attn_weigths/remove_eos_not_permuted_seed_4_compositional_mt_systematicity_s_conj_synthetic_systematicity_synthetic_1_s1_s2_all/generate-test.txt\n",
      "Loading lengths_dict from: /checkpoint/itayitzhak/attn_weigths/remove_eos_not_permuted_seed_4_compositional_mt_systematicity_s_conj_synthetic_systematicity_synthetic_1_s1_s2_all\n",
      "lengths_dict:{14: 15, 15: 68, 16: 119, 17: 146, 18: 85, 19: 44, 20: 17, 21: 5, 22: 1}\n",
      "Trying to load: /checkpoint/itayitzhak/attn_weigths/remove_eos_not_permuted_seed_4_compositional_mt_systematicity_s_conj_synthetic_systematicity_synthetic_1_s1_s2_all/avg_attn_mat_14_(0,_14)_all_s_conj_s1_s2_synthetic.pt\n",
      "Using saved avg matrix at /checkpoint/itayitzhak/attn_weigths/remove_eos_not_permuted_seed_4_compositional_mt_systematicity_s_conj_synthetic_systematicity_synthetic_1_s1_s2_all/avg_attn_mat_14_(0,_14)_all_s_conj_s1_s2_synthetic.pt\n",
      "Percentage of EOS focused heads:  2.78% | Percentage of self focused heads: 8.33% | Percentage of Local focused heads: 8.33%\n",
      "Trying to load: /checkpoint/itayitzhak/attn_weigths/remove_eos_not_permuted_seed_4_compositional_mt_systematicity_s_conj_synthetic_systematicity_synthetic_1_s1_s2_all/avg_attn_mat_15_(15,_82)_all_s_conj_s1_s2_synthetic.pt\n",
      "Using saved avg matrix at /checkpoint/itayitzhak/attn_weigths/remove_eos_not_permuted_seed_4_compositional_mt_systematicity_s_conj_synthetic_systematicity_synthetic_1_s1_s2_all/avg_attn_mat_15_(15,_82)_all_s_conj_s1_s2_synthetic.pt\n",
      "Percentage of EOS focused heads:  2.78% | Percentage of self focused heads: 8.33% | Percentage of Local focused heads: 8.33%\n",
      "Trying to load: /checkpoint/itayitzhak/attn_weigths/remove_eos_not_permuted_seed_4_compositional_mt_systematicity_s_conj_synthetic_systematicity_synthetic_1_s1_s2_all/avg_attn_mat_16_(83,_201)_all_s_conj_s1_s2_synthetic.pt\n",
      "Using saved avg matrix at /checkpoint/itayitzhak/attn_weigths/remove_eos_not_permuted_seed_4_compositional_mt_systematicity_s_conj_synthetic_systematicity_synthetic_1_s1_s2_all/avg_attn_mat_16_(83,_201)_all_s_conj_s1_s2_synthetic.pt\n",
      "Percentage of EOS focused heads:  2.78% | Percentage of self focused heads: 11.11% | Percentage of Local focused heads: 11.11%\n",
      "Trying to load: /checkpoint/itayitzhak/attn_weigths/remove_eos_not_permuted_seed_4_compositional_mt_systematicity_s_conj_synthetic_systematicity_synthetic_1_s1_s2_all/avg_attn_mat_17_(202,_347)_all_s_conj_s1_s2_synthetic.pt\n",
      "Using saved avg matrix at /checkpoint/itayitzhak/attn_weigths/remove_eos_not_permuted_seed_4_compositional_mt_systematicity_s_conj_synthetic_systematicity_synthetic_1_s1_s2_all/avg_attn_mat_17_(202,_347)_all_s_conj_s1_s2_synthetic.pt\n",
      "Percentage of EOS focused heads:  2.78% | Percentage of self focused heads: 8.33% | Percentage of Local focused heads: 8.33%\n",
      "Trying to load: /checkpoint/itayitzhak/attn_weigths/remove_eos_not_permuted_seed_4_compositional_mt_systematicity_s_conj_synthetic_systematicity_synthetic_1_s1_s2_all/avg_attn_mat_18_(348,_432)_all_s_conj_s1_s2_synthetic.pt\n",
      "Using saved avg matrix at /checkpoint/itayitzhak/attn_weigths/remove_eos_not_permuted_seed_4_compositional_mt_systematicity_s_conj_synthetic_systematicity_synthetic_1_s1_s2_all/avg_attn_mat_18_(348,_432)_all_s_conj_s1_s2_synthetic.pt\n",
      "Percentage of EOS focused heads:  2.78% | Percentage of self focused heads: 8.33% | Percentage of Local focused heads: 8.33%\n",
      "Trying to load: /checkpoint/itayitzhak/attn_weigths/remove_eos_not_permuted_seed_4_compositional_mt_systematicity_s_conj_synthetic_systematicity_synthetic_1_s1_s2_all/avg_attn_mat_19_(433,_476)_all_s_conj_s1_s2_synthetic.pt\n",
      "Using saved avg matrix at /checkpoint/itayitzhak/attn_weigths/remove_eos_not_permuted_seed_4_compositional_mt_systematicity_s_conj_synthetic_systematicity_synthetic_1_s1_s2_all/avg_attn_mat_19_(433,_476)_all_s_conj_s1_s2_synthetic.pt\n",
      "Percentage of EOS focused heads:  2.78% | Percentage of self focused heads: 8.33% | Percentage of Local focused heads: 8.33%\n",
      "Trying to load: /checkpoint/itayitzhak/attn_weigths/remove_eos_not_permuted_seed_4_compositional_mt_systematicity_s_conj_synthetic_systematicity_synthetic_1_s1_s2_all/avg_attn_mat_20_(477,_493)_all_s_conj_s1_s2_synthetic.pt\n",
      "Using saved avg matrix at /checkpoint/itayitzhak/attn_weigths/remove_eos_not_permuted_seed_4_compositional_mt_systematicity_s_conj_synthetic_systematicity_synthetic_1_s1_s2_all/avg_attn_mat_20_(477,_493)_all_s_conj_s1_s2_synthetic.pt\n",
      "Percentage of EOS focused heads:  2.78% | Percentage of self focused heads: 8.33% | Percentage of Local focused heads: 8.33%\n",
      "Trying to load: /checkpoint/itayitzhak/attn_weigths/remove_eos_not_permuted_seed_4_compositional_mt_systematicity_s_conj_synthetic_systematicity_synthetic_1_s1_s2_all/avg_attn_mat_21_(494,_498)_all_s_conj_s1_s2_synthetic.pt\n",
      "Using saved avg matrix at /checkpoint/itayitzhak/attn_weigths/remove_eos_not_permuted_seed_4_compositional_mt_systematicity_s_conj_synthetic_systematicity_synthetic_1_s1_s2_all/avg_attn_mat_21_(494,_498)_all_s_conj_s1_s2_synthetic.pt\n",
      "Percentage of EOS focused heads:  2.78% | Percentage of self focused heads: 8.33% | Percentage of Local focused heads: 8.33%\n",
      "Trying to load: /checkpoint/itayitzhak/attn_weigths/remove_eos_not_permuted_seed_4_compositional_mt_systematicity_s_conj_synthetic_systematicity_synthetic_1_s1_s2_all/avg_attn_mat_22_(499,_499)_all_s_conj_s1_s2_synthetic.pt\n",
      "Using saved avg matrix at /checkpoint/itayitzhak/attn_weigths/remove_eos_not_permuted_seed_4_compositional_mt_systematicity_s_conj_synthetic_systematicity_synthetic_1_s1_s2_all/avg_attn_mat_22_(499,_499)_all_s_conj_s1_s2_synthetic.pt\n",
      "Percentage of EOS focused heads:  2.78% | Percentage of self focused heads: 8.33% | Percentage of Local focused heads: 8.33%\n",
      "====================================================================================================\n",
      "Model 8/9\n",
      "====================================================================================================\n",
      "getting samples dict from: /checkpoint/itayitzhak/attn_weigths/not_permuted_seed_4_compositional_mt_systematicity_s_conj_synthetic_systematicity_synthetic_1_s1_s2_all/generate-test.txt\n",
      "Loading lengths_dict from: /checkpoint/itayitzhak/attn_weigths/not_permuted_seed_4_compositional_mt_systematicity_s_conj_synthetic_systematicity_synthetic_1_s1_s2_all\n",
      "lengths_dict:{15: 15, 16: 68, 17: 119, 18: 146, 19: 85, 20: 44, 21: 17, 22: 5, 23: 1}\n",
      "Trying to load: /checkpoint/itayitzhak/attn_weigths/not_permuted_seed_4_compositional_mt_systematicity_s_conj_synthetic_systematicity_synthetic_1_s1_s2_all/avg_attn_mat_15_(0,_14)_all_s_conj_s1_s2_synthetic.pt\n",
      "Using saved avg matrix at /checkpoint/itayitzhak/attn_weigths/not_permuted_seed_4_compositional_mt_systematicity_s_conj_synthetic_systematicity_synthetic_1_s1_s2_all/avg_attn_mat_15_(0,_14)_all_s_conj_s1_s2_synthetic.pt\n",
      "Percentage of EOS focused heads:  0.00% | Percentage of self focused heads: 16.67% | Percentage of Local focused heads: 16.67%\n",
      "Trying to load: /checkpoint/itayitzhak/attn_weigths/not_permuted_seed_4_compositional_mt_systematicity_s_conj_synthetic_systematicity_synthetic_1_s1_s2_all/avg_attn_mat_16_(15,_82)_all_s_conj_s1_s2_synthetic.pt\n",
      "Using saved avg matrix at /checkpoint/itayitzhak/attn_weigths/not_permuted_seed_4_compositional_mt_systematicity_s_conj_synthetic_systematicity_synthetic_1_s1_s2_all/avg_attn_mat_16_(15,_82)_all_s_conj_s1_s2_synthetic.pt\n",
      "Percentage of EOS focused heads:  0.00% | Percentage of self focused heads: 16.67% | Percentage of Local focused heads: 16.67%\n",
      "Trying to load: /checkpoint/itayitzhak/attn_weigths/not_permuted_seed_4_compositional_mt_systematicity_s_conj_synthetic_systematicity_synthetic_1_s1_s2_all/avg_attn_mat_17_(83,_201)_all_s_conj_s1_s2_synthetic.pt\n",
      "Using saved avg matrix at /checkpoint/itayitzhak/attn_weigths/not_permuted_seed_4_compositional_mt_systematicity_s_conj_synthetic_systematicity_synthetic_1_s1_s2_all/avg_attn_mat_17_(83,_201)_all_s_conj_s1_s2_synthetic.pt\n",
      "Percentage of EOS focused heads:  0.00% | Percentage of self focused heads: 16.67% | Percentage of Local focused heads: 16.67%\n",
      "Trying to load: /checkpoint/itayitzhak/attn_weigths/not_permuted_seed_4_compositional_mt_systematicity_s_conj_synthetic_systematicity_synthetic_1_s1_s2_all/avg_attn_mat_18_(202,_347)_all_s_conj_s1_s2_synthetic.pt\n",
      "Using saved avg matrix at /checkpoint/itayitzhak/attn_weigths/not_permuted_seed_4_compositional_mt_systematicity_s_conj_synthetic_systematicity_synthetic_1_s1_s2_all/avg_attn_mat_18_(202,_347)_all_s_conj_s1_s2_synthetic.pt\n",
      "Percentage of EOS focused heads:  0.00% | Percentage of self focused heads: 19.44% | Percentage of Local focused heads: 19.44%\n",
      "Trying to load: /checkpoint/itayitzhak/attn_weigths/not_permuted_seed_4_compositional_mt_systematicity_s_conj_synthetic_systematicity_synthetic_1_s1_s2_all/avg_attn_mat_19_(348,_432)_all_s_conj_s1_s2_synthetic.pt\n",
      "Using saved avg matrix at /checkpoint/itayitzhak/attn_weigths/not_permuted_seed_4_compositional_mt_systematicity_s_conj_synthetic_systematicity_synthetic_1_s1_s2_all/avg_attn_mat_19_(348,_432)_all_s_conj_s1_s2_synthetic.pt\n",
      "Percentage of EOS focused heads:  0.00% | Percentage of self focused heads: 16.67% | Percentage of Local focused heads: 16.67%\n",
      "Trying to load: /checkpoint/itayitzhak/attn_weigths/not_permuted_seed_4_compositional_mt_systematicity_s_conj_synthetic_systematicity_synthetic_1_s1_s2_all/avg_attn_mat_20_(433,_476)_all_s_conj_s1_s2_synthetic.pt\n",
      "Using saved avg matrix at /checkpoint/itayitzhak/attn_weigths/not_permuted_seed_4_compositional_mt_systematicity_s_conj_synthetic_systematicity_synthetic_1_s1_s2_all/avg_attn_mat_20_(433,_476)_all_s_conj_s1_s2_synthetic.pt\n",
      "Percentage of EOS focused heads:  0.00% | Percentage of self focused heads: 16.67% | Percentage of Local focused heads: 16.67%\n",
      "Trying to load: /checkpoint/itayitzhak/attn_weigths/not_permuted_seed_4_compositional_mt_systematicity_s_conj_synthetic_systematicity_synthetic_1_s1_s2_all/avg_attn_mat_21_(477,_493)_all_s_conj_s1_s2_synthetic.pt\n",
      "Using saved avg matrix at /checkpoint/itayitzhak/attn_weigths/not_permuted_seed_4_compositional_mt_systematicity_s_conj_synthetic_systematicity_synthetic_1_s1_s2_all/avg_attn_mat_21_(477,_493)_all_s_conj_s1_s2_synthetic.pt\n",
      "Percentage of EOS focused heads:  0.00% | Percentage of self focused heads: 16.67% | Percentage of Local focused heads: 16.67%\n",
      "Trying to load: /checkpoint/itayitzhak/attn_weigths/not_permuted_seed_4_compositional_mt_systematicity_s_conj_synthetic_systematicity_synthetic_1_s1_s2_all/avg_attn_mat_22_(494,_498)_all_s_conj_s1_s2_synthetic.pt\n",
      "Using saved avg matrix at /checkpoint/itayitzhak/attn_weigths/not_permuted_seed_4_compositional_mt_systematicity_s_conj_synthetic_systematicity_synthetic_1_s1_s2_all/avg_attn_mat_22_(494,_498)_all_s_conj_s1_s2_synthetic.pt\n",
      "Percentage of EOS focused heads:  0.00% | Percentage of self focused heads: 16.67% | Percentage of Local focused heads: 16.67%\n",
      "Trying to load: /checkpoint/itayitzhak/attn_weigths/not_permuted_seed_4_compositional_mt_systematicity_s_conj_synthetic_systematicity_synthetic_1_s1_s2_all/avg_attn_mat_23_(499,_499)_all_s_conj_s1_s2_synthetic.pt\n",
      "Using saved avg matrix at /checkpoint/itayitzhak/attn_weigths/not_permuted_seed_4_compositional_mt_systematicity_s_conj_synthetic_systematicity_synthetic_1_s1_s2_all/avg_attn_mat_23_(499,_499)_all_s_conj_s1_s2_synthetic.pt\n",
      "Percentage of EOS focused heads:  0.00% | Percentage of self focused heads: 13.89% | Percentage of Local focused heads: 13.89%\n",
      "====================================================================================================\n",
      "Model 9/9\n",
      "====================================================================================================\n"
     ]
    }
   ],
   "source": [
    "# all_data_types = [\"not_permuted\", '5gram_permuted', \"permuted\"]\n",
    "all_data_types = [\"not_permuted\", 'remove_eos_not_permuted', 'not_permuted_without_eos']\n",
    "all_data_sizes = ['tiny','small','all']\n",
    "#all_data_sizes = ['all']\n",
    "#all_seeds = [1,2,3,4,5]\n",
    "all_seeds = [4]\n",
    "#all_text_type = ['synthetic', 'semi_natural', 'natural']\n",
    "all_text_type = ['synthetic'] \n",
    "\n",
    "#all_templates = [1,2,3,4,5,6,7,8,9,10]\n",
    "all_templates = [1]\n",
    "all_conds = [('s_conj','s1_s2')]\n",
    "#all_conds = [('s_conj','s1_s2'),('s_conj','s3_s2'),('s_np_vp', 'np')]\n",
    "#all_conds = [('s_conj','s1_s2'),('s_np_vp', 'np')]\n",
    "\n",
    "NUM_HEADS = 8\n",
    "NUM_LAYERS = 6\n",
    "MAX_POSITION = 50\n",
    "\n",
    "recompte_avg_attn_mat = False\n",
    "consistency_only = False\n",
    "is_fine_grained_gloablities = False\n",
    "\n",
    "if consistency_only:\n",
    "    cons_all_models_final_results = get_all_models_final_results(all_data_types,all_data_sizes,all_text_type,all_conds,all_seeds,all_templates,recompte_avg_attn_mat, consistency_only)\n",
    "else:\n",
    "    all_models_final_results = get_all_models_final_results(all_data_types,all_data_sizes,all_text_type,all_conds,all_seeds,all_templates,recompte_avg_attn_mat, consistency_only, is_fine_grained_gloablities)\n",
    "saving_name = f\"all_models_final_results_{str(all_data_types).replace(' ','')}_{str(all_data_sizes).replace(' ','')}_{str(all_text_type).replace(' ','')}_{str(all_conds).replace(' ','')}_{str(all_seeds).replace(' ','')}_{str(all_templates).replace(' ','')}\"\n",
    "pickle.dump(all_models_final_results, open(saving_name, \"wb\"))\n",
    "#pickle.dump(temp_all_models_final_results, open(\"/checkpoint/itayitzhak/temp_all_models_final_results.pt\", \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Plot Consistency (Verna's Plots)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"not_permuted_tiny_synthetic_('s_conj', 's1_s2')_1_compositional_mt__\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-349738ff8185>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     28\u001b[0m             \u001b[0mbleu_annotations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi_seed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_seeds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m                 s1p = [results[f'{trained_data_type}_{data_size}_synthetic_(\\'s_conj\\', \\'s1_s2\\')_{t}_compositional_mt__']['s_conj_s1p_s2_consist'][i_seed]\n\u001b[0m\u001b[1;32m     31\u001b[0m                       \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mall_templates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m                       ]\n",
      "\u001b[0;32m<ipython-input-15-349738ff8185>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     28\u001b[0m             \u001b[0mbleu_annotations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi_seed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_seeds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m                 s1p = [results[f'{trained_data_type}_{data_size}_synthetic_(\\'s_conj\\', \\'s1_s2\\')_{t}_compositional_mt__']['s_conj_s1p_s2_consist'][i_seed]\n\u001b[0m\u001b[1;32m     31\u001b[0m                       \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mall_templates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m                       ]\n",
      "\u001b[0;31mKeyError\u001b[0m: \"not_permuted_tiny_synthetic_('s_conj', 's1_s2')_1_compositional_mt__\""
     ]
    }
   ],
   "source": [
    "sns.set_context(\"talk\")\n",
    "results = pickle.load(open(\"/checkpoint/itayitzhak/all_models_final_results_templates.pt\", 'rb'))\n",
    "results = all_models_final_results\n",
    "all_seeds = range(4,6)\n",
    "all_templates = list(range(1,11))\n",
    "all_trained_data_type = [\"not_permuted\", 'remove_eos_not_permuted']\n",
    "all_text_types = [\"synthetic\"]\n",
    "all_data_sizes = [\"tiny\", \"small\", \"all\"]\n",
    "\n",
    "with_bleu = True\n",
    "with_samples_globalities = True\n",
    "\n",
    "s1p_results = []\n",
    "s3_results = []\n",
    "bleu_results = []\n",
    "models = [] \n",
    "hue = []\n",
    "s1p_all_annotations = []\n",
    "s3_all_annotations = []\n",
    "bleu_all_annotations = []\n",
    "\n",
    "#for text_type in [\"synthetic\", \"semi_natural\", \"natural\"]:\n",
    "for text_type in all_text_types:\n",
    "    for trained_data_type in all_trained_data_type:\n",
    "        for data_size in all_data_sizes:\n",
    "            s1p_annotations = []\n",
    "            s3_annotations = []\n",
    "            bleu_annotations = []\n",
    "            for i_seed, seed in enumerate(all_seeds):\n",
    "                s1p = [results[f'{trained_data_type}_{data_size}_synthetic_(\\'s_conj\\', \\'s1_s2\\')_{t}_compositional_mt__']['s_conj_s1p_s2_consist'][i_seed]\n",
    "                      for t in all_templates\n",
    "                      ]\n",
    "                s3 = [results[f'{trained_data_type}_{data_size}_synthetic_(\\'s_conj\\', \\'s1_s2\\')_{t}_compositional_mt__']['s_conj_s3_s2_consist'][i_seed]\n",
    "                      for t in all_templates\n",
    "                      ]\n",
    "                if with_bleu:\n",
    "                    bleu = [results[f'{trained_data_type}_{data_size}_synthetic_(\\'s_conj\\', \\'s1_s2\\')_{t}_compositional_mt__']['model_bleu'][i_seed]\n",
    "                          for t in all_templates\n",
    "                          ]\n",
    "                s1p_results.append(np.mean(s1p))\n",
    "                s3_results.append(np.mean(s3))\n",
    "                if with_bleu:\n",
    "                    bleu_results.append(np.mean(bleu))\n",
    "                models.append(data_size)\n",
    "                hue.append(trained_data_type)\n",
    "                s1p_annotations.append((np.mean(s1p), trained_data_type, data_size, seed))\n",
    "                s3_annotations.append((np.mean(s3), trained_data_type, data_size, seed))\n",
    "                if with_bleu:    \n",
    "                    bleu_annotations.append((np.mean(bleu), trained_data_type, data_size, seed))\n",
    "            s3_all_annotations.append(min(s3_annotations))\n",
    "            s3_all_annotations.append(max(s3_annotations))\n",
    "            s1p_all_annotations.append(min(s1p_annotations))\n",
    "            s1p_all_annotations.append(max(s1p_annotations))\n",
    "            if with_bleu:\n",
    "                bleu_all_annotations.append(min(bleu_annotations))\n",
    "                bleu_all_annotations.append(max(bleu_annotations))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6, 6))\n",
    "sns.stripplot(x=hue, y=s1p_results, hue=models, dodge=True, zorder=1, label=None, alpha=0.3, size=8, palette=\"viridis\")\n",
    "ax = sns.pointplot(x=hue, y=s1p_results, hue=models,\n",
    "              dodge=.532, join=False, \n",
    "              markers=\"d\", scale=1.05, ci=None, palette=\"viridis\")\n",
    "plt.legend([], [], frameon=False)\n",
    "sns.despine(top=True, right=True)\n",
    "#ax.set_xticklabels([\"synthetic\", \"semi-n.\", \"natural\"])\n",
    "ax.set_xticklabels([\"Org\", \"No-EOS\"])\n",
    "ax.set_ylabel(\"consistency (S1P)\")\n",
    "plt.ylim(0.6, 1)\n",
    "for y, x, m, t in s1p_all_annotations:\n",
    "    if x == \"natural\":\n",
    "        continue\n",
    "    #x = {\"synthetic\": 0, \"semi_natural\": 1, \"natural\": 2}[x]\n",
    "    x = {\"not_permuted\": 0, \"remove_eos_not_permuted\": 1}[x]\n",
    "    if m == \"tiny\":\n",
    "        x -= 0.3\n",
    "    if m == \"small\":\n",
    "        x -=0.1\n",
    "    if m == \"all\":\n",
    "        x += 0.1\n",
    "    plt.text(x, y, t, fontsize=15)\n",
    "#plt.savefig(\"/checkpoint/itayitzhak/figures/s1p.pdf\", bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.figure(figsize=(6, 6))\n",
    "ax = sns.pointplot(x=hue, y=s3_results, hue=models,\n",
    "              dodge=.532, join=False, \n",
    "              markers=\"d\", scale=1.05, ci=None, palette=\"viridis\")\n",
    "sns.stripplot(x=hue, y=s3_results, hue=models, dodge=True, zorder=-1, label=None, alpha=0.3, size=8, palette=\"viridis\")\n",
    "plt.legend([], [], frameon=False) #[\"tiny\", \"small\", \"all\"], bbox_to_anchor=(0.57, 1.05))\n",
    "sns.despine(top=True, right=True)\n",
    "#ax.set_xticklabels([\"synthetic\", \"semi-n.\", \"natural\"])\n",
    "ax.set_xticklabels([\"Org\", \"No-EOS\"])\n",
    "ax.set_ylabel(\"consistency S3_S2\")\n",
    "plt.ylim(0.2, 1)\n",
    "for y, x, m, t in s3_all_annotations:\n",
    "    if x == \"natural\":\n",
    "        continue\n",
    "    #x = {\"synthetic\": 0, \"semi_natural\": 1, \"natural\": 2}[x]\n",
    "    x = {\"not_permuted\": 0, \"remove_eos_not_permuted\": 1}[x]\n",
    "    if m == \"tiny\":\n",
    "        x -= 0.3\n",
    "    if m == \"small\":\n",
    "        x -=0.05\n",
    "    if m == \"all\":\n",
    "        x += 0.2\n",
    "    plt.text(x, y, t, fontsize=15)\n",
    "#ax.set_yticks([])\n",
    "#plt.savefig(\"/checkpoint/itayitzhak/figures/s3.pdf\", bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(6, 6))\n",
    "ax = sns.pointplot(x=hue, y=bleu_results, hue=models,\n",
    "              dodge=.532, join=False, \n",
    "              markers=\"d\", scale=1.05, ci=None, palette=\"viridis\")\n",
    "sns.stripplot(x=hue, y=s3_results, hue=models, dodge=True, zorder=-1, label=None, alpha=0.3, size=8, palette=\"viridis\")\n",
    "plt.legend([], [], frameon=False) #[\"tiny\", \"small\", \"all\"], bbox_to_anchor=(0.57, 1.05))\n",
    "sns.despine(top=True, right=True)\n",
    "#ax.set_xticklabels([\"synthetic\", \"semi-n.\", \"natural\"])\n",
    "ax.set_xticklabels([\"Org\", \"No-EOS\"])\n",
    "ax.set_ylabel(\"BLEU\")\n",
    "plt.ylim(20, 26)\n",
    "for y, x, m, t in bleu_all_annotations:\n",
    "    if x == \"natural\":\n",
    "        continue\n",
    "    #x = {\"synthetic\": 0, \"semi_natural\": 1, \"natural\": 2}[x]\n",
    "    x = {\"not_permuted\": 0, \"remove_eos_not_permuted\": 1}[x]\n",
    "    if m == \"tiny\":\n",
    "        x -= 0.3\n",
    "    if m == \"small\":\n",
    "        x -=0.05\n",
    "    if m == \"all\":\n",
    "        x += 0.2\n",
    "    plt.text(x, y, t, fontsize=15)\n",
    "#ax.set_yticks([])\n",
    "#plt.savefig(\"/checkpoint/itayitzhak/figures/s3.pdf\", bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Create DF for plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_for_plot(value):\n",
    "    if value == 'trained_data_type': return 'Training Data Type'\n",
    "    if value == 'not_permuted_without_eos': return 'Trained With Original Data'\n",
    "    if value == 'not_permuted': return 'Trained With Original Data (Analysis With EOS)'\n",
    "    if value == 'remove_eos_not_permuted': return 'Trained Without EOS'\n",
    "    if value == 'model_distance_weighted_median': return 'Distance Weighted Median'\n",
    "    if value == 'model_globality_scores': return 'Globality'\n",
    "    if value == 'trained_data_size': return 'Data Size'\n",
    "    if value == 'model_bleu': return 'BLEU'\n",
    "    if value == 'distance_weighted_median': return 'Distance Weighted Median Distrubation'     \n",
    "    if value == 's_conj_s1p_s2_consist': return 's_conj s1p_s2 Consistency'  \n",
    "    if value == 's_conj_s3_s2_consist': return 's_conj s3_s2 Consistency'\n",
    "    if value == 's_np_vp_np_prime_consist': return 's_np_vp np_prime Consistency'\n",
    "    if value == 's_np_vp_vp_prime_consist': return 's_np_vp vp_prime Consistency'\n",
    "    if type(value)==type([]) and type(value[0])==type([]): return flatten(value)# nested list\n",
    " \n",
    "    return value\n",
    "\n",
    "def create_df_from_results(models_final_results, wanted_keys, wanted_y, wanted_conds, templates_to_use, explode_wanted_y=True):\n",
    "    data_to_plot = dict()\n",
    "    for wanted_key in wanted_keys:\n",
    "        data_to_plot[change_for_plot(wanted_key)] = []\n",
    "    data_to_plot['model_name'] = []\n",
    "        \n",
    "    for cur_model_path, results in models_final_results.items():\n",
    "        if results['conds'] == wanted_conds and results['template'] in templates_to_use:\n",
    "            print(f\"cur_model_path:{cur_model_path}\")\n",
    "            #data_to_plot['model_name'].append(cur_model_path)\n",
    "            max_values_number = 0\n",
    "            for key, value in results.items():\n",
    "                if key in wanted_keys:\n",
    "                    print(key)\n",
    "                    data_to_plot[change_for_plot(key)].append(change_for_plot(value))\n",
    "                    if type(value) == type([]): # added after get_bar_plot\n",
    "                        max_values_number = max(max_values_number,len(value))\n",
    "                    else:\n",
    "                        max_values_number = max(max_values_number,1)\n",
    "    models_names = list(data_to_plot['model_name'])\n",
    "    print(f\"models_names:{models_names}\")\n",
    "    print(f\"data_to_plot:{data_to_plot}\")\n",
    "    data_to_plot = pd.DataFrame(data_to_plot, index = models_names)\n",
    "    if explode_wanted_y:\n",
    "        data_to_plot = data_to_plot.explode(wanted_y)\n",
    "\n",
    "    return data_to_plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Bar Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bar_plot(models_final_results, wanted_keys, wanted_y, ylim, wanted_conds=('s_conj','s1_s2'),templates_to_use=[i for i in range(1,11)]):\n",
    "    data_to_plot = create_df_from_results(models_final_results, wanted_keys, wanted_y, wanted_conds, templates_to_use)\n",
    "    sns.set_context('paper')\n",
    "    sns.set(rc={'figure.figsize':(8,4)})\n",
    "    plt.legend(bbox_to_anchor=(1.01, 1), borderaxespad=0)\n",
    "    plt.tight_layout()\n",
    "    sns.set(font_scale=0.8)\n",
    "    plt.ylim(ylim[0], ylim[1])\n",
    "\n",
    "    ax = sns.scatterplot(x = 'Data Size', y = wanted_y, hue = 'Training Data Type', data = data_to_plot, s=80)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "get_bar_plot(all_models_final_results,\n",
    "             ['trained_data_type','trained_data_size','model_distance_weighted_median','model_globality_scores'],\n",
    "             wanted_y='Distance Weighted Median', ylim=(2,8),\n",
    "             wanted_conds = ('s_conj','s1_s2')\n",
    "            )\n",
    "\n",
    "get_bar_plot(all_models_final_results,\n",
    "             ['trained_data_type','trained_data_size','model_distance_weighted_median','model_globality_scores'],\n",
    "             wanted_y='Globality', ylim=(0.21,0.3),\n",
    "             wanted_conds = ('s_conj','s1_s2')\n",
    "            )\n",
    "\n",
    "get_bar_plot(all_models_final_results,\n",
    "             ['trained_data_type','trained_data_size','model_bleu'],\n",
    "             wanted_y='BLEU', ylim=(20,26),\n",
    "             wanted_conds = ('s_conj','s1_s2')\n",
    "            )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "get_bar_plot(all_models_final_results,\n",
    "             ['trained_data_type','trained_data_size','model_distance_weighted_median','model_globality_scores'],\n",
    "             wanted_y='Distance Weighted Median', ylim=(2,8),\n",
    "             wanted_conds = ('s_conj','s1_s2'),\n",
    "             templates_to_use=[2]\n",
    "            )\n",
    "\n",
    "get_bar_plot(all_models_final_results,\n",
    "             ['trained_data_type','trained_data_size','model_distance_weighted_median','model_globality_scores'],\n",
    "             wanted_y='Globality', ylim=(0.21,0.3),\n",
    "             wanted_conds = ('s_conj','s1_s2'),\n",
    "             templates_to_use=[2]\n",
    "            )\n",
    "\n",
    "get_bar_plot(all_models_final_results,\n",
    "             ['trained_data_type','trained_data_size','model_bleu'],\n",
    "             wanted_y='BLEU', ylim=(20,26),\n",
    "             wanted_conds = ('s_conj','s1_s2'),\n",
    "             templates_to_use=[2]\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "get_bar_plot(all_models_final_results,\n",
    "             ['trained_data_type','trained_data_size','s_conj_s1p_s2_consist'],\n",
    "             wanted_y='s_conj s1p_s2 Consistency', ylim=(0,1),\n",
    "             wanted_conds = ('s_conj','s1_s2')\n",
    "            )\n",
    "\n",
    "get_bar_plot(all_models_final_results,\n",
    "             ['trained_data_type','trained_data_size','s_conj_s3_s2_consist'],\n",
    "             wanted_y='s_conj s3_s2 Consistency', ylim=(0,1),\n",
    "             wanted_conds = ('s_conj','s1_s2')\n",
    "            )\n",
    "\n",
    "\n",
    "get_bar_plot(all_models_final_results,\n",
    "             ['trained_data_type','trained_data_size','s_np_vp_np_prime_consist'],\n",
    "             wanted_y='s_np_vp np_prime Consistency', ylim=(0,1),\n",
    "             wanted_conds = ('s_np_vp','np')\n",
    "            )\n",
    "\n",
    "get_bar_plot(all_models_final_results,\n",
    "             ['trained_data_type','trained_data_size','s_np_vp_vp_prime_consist'],\n",
    "             wanted_y='s_np_vp vp_prime Consistency', ylim=(0,1),\n",
    "             wanted_conds = ('s_np_vp','np')\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "get_bar_plot(all_models_final_results,\n",
    "             ['trained_data_type','trained_data_size','s_conj_s1p_s2_consist'],\n",
    "             wanted_y='s_conj s1p_s2 Consistency', ylim=(0,1),\n",
    "             wanted_conds = ('s_conj','s1_s2')\n",
    "            )\n",
    "\n",
    "get_bar_plot(all_models_final_results,\n",
    "             ['trained_data_type','trained_data_size','s_conj_s3_s2_consist'],\n",
    "             wanted_y='s_conj s3_s2 Consistency', ylim=(0,1),\n",
    "             wanted_conds = ('s_conj','s1_s2')\n",
    "            )\n",
    "\n",
    "\n",
    "get_bar_plot(all_models_final_results,\n",
    "             ['trained_data_type','trained_data_size','s_np_vp_np_prime_consist'],\n",
    "             wanted_y='s_np_vp np_prime Consistency', ylim=(0,1),\n",
    "             wanted_conds = ('s_np_vp','np')\n",
    "            )\n",
    "\n",
    "get_bar_plot(all_models_final_results,\n",
    "             ['trained_data_type','trained_data_size','s_np_vp_vp_prime_consist'],\n",
    "             wanted_y='s_np_vp vp_prime Consistency', ylim=(0,1),\n",
    "             wanted_conds = ('s_np_vp','np')\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Violin Plots and p-values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "def show_violin_new(models_final_results, wanted_keys, wanted_y, wanted_conds=('s_conj','s1_s2')):\n",
    "    data_to_plot = create_df_from_results(models_final_results, wanted_keys, wanted_y, wanted_conds)\n",
    "    labels = (data_to_plot['Training Data Type'] + data_to_plot['Data Size']).unique()\n",
    "    dists = list(data_to_plot[wanted_y])\n",
    "    fig = plt.figure()\n",
    "    ax1 = fig.add_axes([0,0,1,1])\n",
    "    #print(f\"dists:{dists}\")\n",
    "    bp_eos = ax1.violinplot(dists, showmeans=True)\n",
    "    ax1.set_title(wanted_y)\n",
    "    ax1.set_xticks([1,2])\n",
    "    ax1.set_xticklabels(labels, rotation=0)\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "show_violin_new(\n",
    "    all_models_final_results,\n",
    "    ['trained_data_type','trained_data_size','distance_weighted_median'],\n",
    "    'Distance Weighted Median Distrubation', wanted_conds=('s_conj','s1_s2'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_violin(dists, title, labels):\n",
    "    # df_all_eos_foucesed_heads = pd.DataFrame(all_eos_foucesed_heads).transpose()\n",
    "    # ax = sns.violinplot(x=[\"a\", \"b\"],data=df_all_eos_foucesed_heads)\n",
    "\n",
    "    # Create a figure instance\n",
    "    fig = plt.figure()\n",
    "\n",
    "    #fig, (ax1, ax2, ax3) = plt.subplots(nrows=1, ncols=3, figsize=(15,6), sharex=False)\n",
    "\n",
    "    # Create an axes instance\n",
    "    ax1 = fig.add_axes([0,0,1,1])\n",
    "    # ax2 = fig.add_axes([0,0,1,1])\n",
    "    # ax3 = fig.add_axes([0,0,1,1])\n",
    "\n",
    "    # Create the boxplot\n",
    "    #ax1.xlabels([\"a\",\"b\",\"c\",\"a\",\"b\",\"c\"])\n",
    "    bp_eos = ax1.violinplot(dists, showmeans=True)\n",
    "\n",
    "    # plt.show()\n",
    "    # bp = ax.violinplot(all_distance_weighted_median)\n",
    "    # plt.show()\n",
    "    # bp = ax.violinplot(all_globality_scores)\n",
    "    ax1.set_title(title)\n",
    "\n",
    "    #ax1.set_xticklabels([\"0\",\"Not Permuted (Small)\",\"5-gram Permuted (Small)\",\"Permuted (Small)\",\"Not Permuted (All)\",\"5-gram Permuted (All)\",\"Permuted (All)\"], rotation=90)\n",
    "    ax1.set_xticks([1,2])\n",
    "    ax1.set_xticklabels(labels, rotation=0)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "show_violin(all_eos_foucesed_heads, 'EOS Focus', [\"Original data (All)\",\"Remove EOS (All)\"])\n",
    "show_violin(all_self_heads, 'Self Focus', [\"Original data (All)\",\"Remove EOS (All)\"])\n",
    "show_violin(all_local_heads, 'Local Focus', [\"Original data (All)\",\"Remove EOS (All)\"])\n",
    "show_violin(all_distance_weighted_median, 'Weighted Median Distance', [\"Original data (All)\",\"Remove EOS (All)\"])\n",
    "show_violin(all_globality_scores, 'Globality Score', [\"Original data (All)\",\"Remove EOS (All)\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_single_ttest(H_0,H_1,name_1,name_2):\n",
    "    print(f\"T-test for {name_1} vs {name_2}\",end=':')\n",
    "    print(f\"p-value <= {stats.ttest_ind(H_0, H_1)[1]:.4f}\")\n",
    "    \n",
    "def calc_ttest(data_for_ttest):\n",
    "#     print(\"T-test for Not Permuted vs 5-gram Permuted (Small)\",end=':')\n",
    "#     print(f\"p-value <= {stats.ttest_ind(data_for_ttest[0], data_for_ttest[1])[1]:.2f}\")\n",
    "    print_single_ttest(data_for_ttest[0],data_for_ttest[1],\"Not Permuted\",\"5-gram Permuted (Small)\")\n",
    "    print(\"T-test for Not Permuted vs Permuted (Small)\",end=':')\n",
    "    print(f\"p-value <= {stats.ttest_ind(data_for_ttest[0], data_for_ttest[2])[1]:.2f}\")\n",
    "    print(\"T-test for Not Permuted vs 5-gram Permuted (All)\",end=':')\n",
    "    print(f\"p-value <= {stats.ttest_ind(data_for_ttest[3], data_for_ttest[4])[1]:.2f}\")\n",
    "    print(\"T-test for Not Permuted vs Permuted (All)\",end=':')\n",
    "    #print(stats.ttest_ind(all_distance_weighted_median[3], all_distance_weighted_median[5]))\n",
    "    print(f\"p-value <= {stats.ttest_ind(data_for_ttest[3], data_for_ttest[5])[1]:.2f}\")\n",
    "# calc_ttest(all_distance_weighted_median)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_single_ttest(all_eos_foucesed_heads[0],all_eos_foucesed_heads[1],\"EOS Original data (All)\",\"EOS Remove EOS (All)\")\n",
    "print_single_ttest(all_self_heads[0],all_self_heads[1],\"SELF Original data (All)\",\" SELF Remove EOS (All)\")\n",
    "print_single_ttest(all_local_heads[0],all_local_heads[1],\"LOCAL Original data (All)\",\"Local Remove EOS (All)\")\n",
    "print_single_ttest(all_distance_weighted_median[0],all_distance_weighted_median[1],\"Weighted Distance Original data (All)\",\"Weighted Distance Remove EOS (All)\")\n",
    "print_single_ttest(all_globality_scores[0],all_globality_scores[1],\"Globality Original data (All)\",\"Gloablity Remove EOS (All)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_all_eos_foucesed_heads = pd.DataFrame(all_eos_foucesed_heads).transpose()\n",
    "# ax = sns.violinplot(x=[\"a\", \"b\"],data=df_all_eos_foucesed_heads)\n",
    "\n",
    "# Create a figure instance\n",
    "fig = plt.figure()\n",
    "\n",
    "# Create an axes instance\n",
    "ax1 = fig.add_axes([0,0,1,1])\n",
    "\n",
    "# Create the boxplot\n",
    "bp_eos = ax1.violinplot(all_seeds_distance_weighted_median, showmeans=True)\n",
    "\n",
    "ax1.set_title('Globality Scores')\n",
    "ax1.set_xticklabels([\"0\",\"Not Permuted (Small)\",\"5-gram Permuted (Small)\",\"Permuted (Small)\",\"Not Permuted (All)\",\"5-gram Permuted (All)\",\"Permuted (All)\"], rotation=90)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Consistency Vs. Globality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_context(\"talk\")\n",
    "#results = pickle.load(open(\"/checkpoint/itayitzhak/all_models_final_results_templates.pt\", 'rb'))\n",
    "results = temp_all_models_final_results\n",
    "all_seeds = range(4,5)\n",
    "all_templates = list(range(1,2))\n",
    "all_trained_data_type = ['remove_eos_not_permuted']#[\"not_permuted\"]#[\"not_permuted\", 'remove_eos_not_permuted']\n",
    "all_text_types = [\"synthetic\"]\n",
    "all_data_sizes = [\"all\"]#[\"tiny\", \"small\", \"all\"]\n",
    "\n",
    "with_samples_globalities = True\n",
    "\n",
    "s1p_results = []\n",
    "s3_results = []\n",
    "bleu_results = []\n",
    "models = [] \n",
    "hue = []\n",
    "s1p_all_annotations = []\n",
    "s3_all_annotations = []\n",
    "bleu_all_annotations = []\n",
    "\n",
    "#for text_type in [\"synthetic\", \"semi_natural\", \"natural\"]:\n",
    "for text_type in all_text_types:\n",
    "    for trained_data_type in all_trained_data_type:\n",
    "        for data_size in all_data_sizes:\n",
    "            s1p_annotations = []\n",
    "            s3_annotations = []\n",
    "            bleu_annotations = []\n",
    "            #for t in range(1, 11):\n",
    "            for i_seed, seed in enumerate(all_seeds):\n",
    "    #             size_results = [results[(f\"transformer_{model}_{seed}\", seed, \"s_conj\", data_type, t)]\n",
    "    #                             for seed in [1, 2, 3, 4, 5]]\n",
    "#                 s1p = results[f'{trained_data_type}_{data_size}_synthetic_(\\'s_conj\\', \\'s1_s2\\')_{t}_compositional_mt__']['s_conj_s1p_s2_consist']\n",
    "#                 s3 = results[f'{trained_data_type}_{data_size}_synthetic_(\\'s_conj\\', \\'s1_s2\\')_{t}_compositional_mt__']['s_conj_s3_s2_consist']\n",
    "#                 bleu = results[f'{trained_data_type}_{data_size}_synthetic_(\\'s_conj\\', \\'s1_s2\\')_{t}_compositional_mt__']['model_bleu']\n",
    "#                 if trained_data_type == \"not_permuted\" and data_size != 'all' and seed == 3:\n",
    "#                         continue\n",
    "                print(f\"seed={seed}\")\n",
    "                print([results[f'{trained_data_type}_{data_size}_synthetic_(\\'s_conj\\', \\'s1_s2\\')_{t}_compositional_mt__']['all_sampels_s_conj_s1p_s2_consist'][i_seed]\n",
    "                      for t in all_templates])\n",
    "                samples_s1p = [results[f'{trained_data_type}_{data_size}_synthetic_(\\'s_conj\\', \\'s1_s2\\')_{t}_compositional_mt__']['all_sampels_s_conj_s1p_s2_consist'][i_seed]\n",
    "                      for t in all_templates\n",
    "                      ]\n",
    "                samples_s3 = [results[f'{trained_data_type}_{data_size}_synthetic_(\\'s_conj\\', \\'s1_s2\\')_{t}_compositional_mt__']['all_sampels_s_conj_s3_s2_consist'][i_seed]\n",
    "                      for t in all_templates\n",
    "                      ]\n",
    "                samples_globalities = [results[f'{trained_data_type}_{data_size}_synthetic_(\\'s_conj\\', \\'s1_s2\\')_{t}_compositional_mt__']['all_sampels_gloablity'][i_seed]\n",
    "                  for t in all_templates\n",
    "                  ]\n",
    "                samples_weighted_median_distance = [results[f'{trained_data_type}_{data_size}_synthetic_(\\'s_conj\\', \\'s1_s2\\')_{t}_compositional_mt__']['all_sampels_weighted_median_distance'][i_seed]\n",
    "                  for t in all_templates\n",
    "                  ]\n",
    "\n",
    "                models.append(data_size)\n",
    "                hue.append(trained_data_type)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def plot_globalality_to_consistenecy(models_final_results, wanted_keys, wanted_conds=('s_conj','s1_s2'),templates_to_use=[1]):\n",
    "#     data_to_plot = create_df_from_results(models_final_results, wanted_keys, False, wanted_conds, templates_to_use, explode_wanted_y=False)\n",
    "#     print(f\"data_to_plot={data_to_plot}\")\n",
    "#     sns.set_context('paper')\n",
    "#     sns.set(rc={'figure.figsize':(6,4)})\n",
    "#     plt.legend(bbox_to_anchor=(1.01, 1), borderaxespad=0)\n",
    "#     plt.tight_layout()\n",
    "#     sns.set(font_scale=0.8)\n",
    "#     plt.ylim(0.26,0.32)\n",
    "#     #ax = sns.scatterplot(x = 'Data Size', y = wanted_y, hue = 'Training Data Type', data = data_to_plot, s=80)\n",
    "#     #fig = plt.figure()\n",
    "#     #ax = fig.add_subplot(111, projection = '3d')\n",
    "#     #ax.scatter(x = data_to_plot[\"samples_s1p\"], y = data_to_plot[\"samples_globalities\"], z = data_to_plot[\"samples_s3\"], s=80)\n",
    "#     #ax = sns.scatterplot(x = wanted_keys[0], y = wanted_keys[1], data = data_to_plot, s=80)\n",
    "#     ax = plt.scatter(x = data_to_plot[wanted_keys[0]], y = data_to_plot[wanted_keys[1]])\n",
    "#     ax.set_xticks(range(0,2))\n",
    "#     ax.set_xticklabels(['Not Consistent','Consistent'])\n",
    "#     plt.show()\n",
    "    \n",
    "# plot_globalality_to_consistenecy(temp_all_models_final_results, [\"all_sampels_s_conj_s1p_s2_consist\", \"all_sampels_gloablity\", \"all_sampels_weighted_median_distance\"], wanted_conds=('s_conj','s1_s2'),templates_to_use=[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_to_plot = {\n",
    "                \"samples_s1p\": samples_s1p[0],\n",
    "                \"samples_s3\": samples_s3[0],\n",
    "                #\"s1p_not_consist_glob_results\": s1p_not_consist_glob_results,\n",
    "                \"samples_globalities\": samples_globalities[0],\n",
    "                \"samples_weighted_median_distance\": samples_weighted_median_distance[0],\n",
    "                # s3_consist_glob_results.append(samples_globalities[samples_s3])\n",
    "                # s1p_not_consist_glob_results.append(samples_globalities[[ not x for x in samples_s1p]])\n",
    "                # s3_not_consist_glob_results.append(samples_globalities[[ not x for x in samples_s3]])\n",
    "                \n",
    "                # s1p_consist_wmd_results.append(samples_globalities[samples_s1p])\n",
    "                # s3_consist_wmd_results.append(samples_globalities[samples_s3])\n",
    "                # s1p_not_consist_wmd_results.append(samples_globalities[[not x for x in samples_s1p]])\n",
    "                # s3_not_consist_wmd_results.append(samples_globalities[[not x for x in samples_s3]])\n",
    "}\n",
    "data_to_plot = pd.DataFrame(data_to_plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_to_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logsitic regression\n",
    "from sklearn import datasets\n",
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "np_samples_globalities = np.array(samples_globalities)\n",
    "np_samples_s1p = np.array(samples_s1p)\n",
    "print(f\"np_samples_globalities.shape={np_samples_globalities.shape}\")\n",
    "print(f\"baseline:{(np_samples_s1p.sum())/500}\")\n",
    "w = {0:(500-np_samples_s1p.sum())/500,1:np_samples_s1p.sum()/500}\n",
    "print(w)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    np_samples_globalities[0], np_samples_s1p[0], test_size=0.10, random_state=0)\n",
    "LRG = linear_model.LogisticRegression(\n",
    "   random_state = 0,solver = 'liblinear',multi_class = 'auto', class_weight=w)\n",
    "\n",
    "\n",
    "LRG.fit(X_train.reshape(-1, 1), y_train)\n",
    "LRG.score(X_test.reshape(-1, 1), y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_context('paper')\n",
    "sns.set(rc={'figure.figsize':(6,4)})\n",
    "plt.legend(bbox_to_anchor=(1.01, 1), borderaxespad=0)\n",
    "plt.tight_layout()\n",
    "sns.set(font_scale=0.8)\n",
    "plt.ylim(0.18,0.21)\n",
    "#ax = sns.scatterplot(x = 'Data Size', y = wanted_y, hue = 'Training Data Type', data = data_to_plot, s=80)\n",
    "#fig = plt.figure()\n",
    "#ax = fig.add_subplot(111, projection = '3d')\n",
    "#ax.scatter(x = data_to_plot[\"samples_s1p\"], y = data_to_plot[\"samples_globalities\"], z = data_to_plot[\"samples_s3\"], s=80)\n",
    "ax = sns.scatterplot(x = \"samples_s1p\", y = \"samples_globalities\", data = data_to_plot, s=80)\n",
    "ax.set_xticks(range(0,2))\n",
    "ax.set_xticklabels(['Not Consistent','Consistent'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.ylim(3.8,5.8)\n",
    "#ax = sns.scatterplot(x = 'Data Size', y = wanted_y, hue = 'Training Data Type', data = data_to_plot, s=80)\n",
    "ax = sns.scatterplot(x = \"samples_s1p\", y = \"samples_weighted_median_distance\", data = data_to_plot, s=80)\n",
    "ax.set_xticks(range(0,2))\n",
    "ax.set_xticklabels(['Not Consistent','Consistent'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.ylim(0.18,0.21)\n",
    "#ax = sns.scatterplot(x = 'Data Size', y = wanted_y, hue = 'Training Data Type', data = data_to_plot, s=80)\n",
    "ax = sns.scatterplot(x = \"samples_s3\", y = \"samples_globalities\", data = data_to_plot, s=80)\n",
    "ax.set_xticks(range(0,2))\n",
    "ax.set_xticklabels(['Not Consistent','Consistent'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.ylim(3.8,5.8)\n",
    "#ax = sns.scatterplot(x = 'Data Size', y = wanted_y, hue = 'Training Data Type', data = data_to_plot, s=80)\n",
    "ax = sns.scatterplot(x = \"samples_s3\", y = \"samples_weighted_median_distance\", data = data_to_plot, s=80)\n",
    "ax.set_xticks(range(0,2))\n",
    "ax.set_xticklabels(['Not Consistent','Consistent'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Histograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_hist(cur_model_path, model_results, y_type):\n",
    "    #eos_foucesed_heads, self_heads, local_heads, distance_weighted_median, globality_scores = calc_percentage_of_attn_head_type(avg_attn_matrix)\n",
    "    if y_type == 'EOS':\n",
    "        data_to_plot = model_results['eos_foucesed_heads']\n",
    "        xlim = (0,1.0)\n",
    "        color = \"blue\"\n",
    "    if y_type == 'Local':\n",
    "        data_to_plot = model_results['local_heads']\n",
    "        color = 'red'\n",
    "        xlim = (0,1.0)\n",
    "    if y_type == 'Self':\n",
    "        data_to_plot = model_results['self_heads']\n",
    "        color = 'green'\n",
    "        xlim = (0,1.0)\n",
    "    if y_type == 'Distance weighted median':\n",
    "        data_to_plot = model_results['distance_weighted_median']\n",
    "        color = 'orange'\n",
    "        xlim = (0,16)\n",
    "    if y_type == 'Globality Score':\n",
    "        data_to_plot = model_results['globality_scores']\n",
    "        color = 'grey'\n",
    "        xlim = (0,0.5)\n",
    "        \n",
    "        #print(f\"len(data_to_plot):{len(data_to_plot)}\")\n",
    "        #print(f\"len(list(model_results['lengths_dict'].values())):{len(list(model_results['lengths_dict'].values()))}\")\n",
    "        #print(f\"np.array(data_to_plot).shape:{np.array(data_to_plot).shape}\")\n",
    "    data_to_plot = np.average(data_to_plot, weights=list(model_results['lengths_dict'].values()), axis = 0)\n",
    "        #print(f\"data_to_plot.shape:{data_to_plot.shape}\")\n",
    "    plt.hist(data_to_plot, alpha=0.5, label=y_type, histtype='bar', color=f'{color}')\n",
    "\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.ylabel('Number of Heads')\n",
    "    plt.xlabel(f'{y_type} Attention')\n",
    "    plt.ylim(0,24)\n",
    "    plt.xlim(xlim[0],xlim[1])\n",
    "    \n",
    "    if model_results['trained_data_type'] == 'remove_eos_not_permuted':\n",
    "        data_type = 'Without EOS'\n",
    "    if model_results['trained_data_type'] == 'not_permuted':\n",
    "        data_type = 'Original_(with EOS)'\n",
    "    if model_results['trained_data_type'] == 'not_permuted_without_eos':\n",
    "        data_type = 'Original'\n",
    "    if model_results['trained_data_size'] == 'tiny':\n",
    "        data_size = 'Small'\n",
    "    if model_results['trained_data_size'] == 'small':\n",
    "        data_size = 'Medium'\n",
    "    if model_results['trained_data_size'] == 'all':\n",
    "        data_size = 'Large'\n",
    "        \n",
    "    plt.title(f\"{data_size} {data_type}  {model_results['text_type']} systematicity {model_results['template']}\")\n",
    "\n",
    "    plt.show()\n",
    "    #plt.savefig(f\"EOS_{cond}_{cond_name}_Train_size={size}_Length={LENGTH}.pdf\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#all_models_final_results\n",
    "for cur_model_path, results in temp_all_models_final_results.items():\n",
    "    print(cur_model_path)\n",
    "    print(results['eos_foucesed_heads'][0][:10])\n",
    "    plot_hist(cur_model_path, results, \"EOS\")\n",
    "    plot_hist(cur_model_path, results, \"Local\")\n",
    "    plot_hist(cur_model_path, results, \"Self\")\n",
    "    plot_hist(cur_model_path, results, \"Distance weighted median\")\n",
    "    plot_hist(cur_model_path, results, \"Globality Score\")\n",
    "    print(\"=\"*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Layer Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_focus_across_layers(cur_focus, label, color='blue'):\n",
    "    layer_mean = []\n",
    "    layer_percentile = []\n",
    "    for i in range(0,NUM_LAYERS*NUM_HEADS,NUM_HEADS):\n",
    "        layer_mean.append(sum(cur_focus[i:i+NUM_HEADS]) / NUM_HEADS)\n",
    "        layer_percentile.append(np.percentile(cur_focus[i:i+NUM_HEADS], 90))\n",
    "\n",
    "    if label == 'EOS': color = \"blue\"\n",
    "    if label == 'Local': color = 'red'\n",
    "    if label == 'Self': color = 'green'\n",
    "    if label == 'Distance weighted median': color = 'orange'\n",
    "    if label == 'Globality Score': color = 'grey'\n",
    "\n",
    "    plt.plot(layer_percentile, alpha=1, label=label, color=color, linewidth=3)\n",
    "    #plt.hist(self_heads, alpha=0.5, label='Self', histtype='bar')\n",
    "    #plt.hist(local_heads, alpha=0.5, label='Local', histtype='bar')\n",
    "\n",
    "    plt.legend(loc='lower right')\n",
    "    #plt.xticks([i for i in range(0,17)])\n",
    "    plt.ylabel('Attention Weight')\n",
    "    plt.xlabel('Layer')\n",
    "    plt.ylim(0,1.0)\n",
    "    if label == 'Median Distance' or label == 'Distance weighted median': # weighted median distance\n",
    "        plt.ylim(0,17)\n",
    "    if label == \"Globality Score\":\n",
    "        plt.ylim(0.3,0.5)\n",
    "        \n",
    "    #plt.title(f\"{cond} {cond_name} | Train_size={size} | Length={LENGTH}\")\n",
    "\n",
    "    #plt.axvline(x=1/LENGTH, color='red', linewidth=0.5)\n",
    "    #plt.plot([1/LENGTH]*len(local_heads), label='Uniform Weight')\n",
    "\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    print(f\"Model:{cur_model_path}\")\n",
    "display_focus_across_layers(eos_foucesed_heads, label='EOS-focus')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "def data_across_lengths(model_results, wanted_focus):\n",
    "    return np.average(model_results[wanted_focus], weights=list(model_results['lengths_dict'].values()), axis = 0)\n",
    "\n",
    "for cur_model_path, results in all_models_final_results.items():\n",
    "    print(cur_model_path)\n",
    "    display_focus_across_layers(data_across_lengths(results, 'eos_foucesed_heads'), 'EOS', color='blue')\n",
    "    display_focus_across_layers(data_across_lengths(results, 'local_heads'), 'Local', color='blue')\n",
    "    display_focus_across_layers(data_across_lengths(results, 'self_heads'), 'Self', color='blue')\n",
    "    display_focus_across_layers(data_across_lengths(results, 'distance_weighted_median'), 'Distance weighted median', color='blue')\n",
    "    display_focus_across_layers(data_across_lengths(results, 'globality_scores'), 'Globality Score', color='blue')\n",
    "    print(\"=\"*100)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Legacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_threshold = 0.35 # 2*1/LENGTH\n",
    "majority_threshold = 0.9\n",
    "eos_foucesed_heads, self_heads, local_heads, distance_weighted_median, globality_scores = calc_percentage_of_attn_head_type(avg_attn_matrix, weight_threshold, majority_threshold)\n",
    "\n",
    "#print(eos_foucesed_heads)\n",
    "#plt.hist(eos_foucesed_heads, np.unique(eos_foucesed_heads), alpha=0.5, label='EOS')\n",
    "#plt.hist(local_heads, np.unique(local_heads), alpha=0.5, label='Self')\n",
    "plt.hist(eos_foucesed_heads, alpha=0.5, label='EOS', histtype='bar')\n",
    "#plt.hist(self_heads, alpha=0.5, label='Self', histtype='bar')\n",
    "#plt.hist(local_heads, alpha=0.5, label='Local', histtype='bar')\n",
    "\n",
    "plt.legend(loc='upper right')\n",
    "#plt.xticks([i for i in range(0,17)])\n",
    "plt.ylabel('Number of Heads')\n",
    "plt.xlabel('Attention Weight To EOS')\n",
    "plt.ylim(0,20)\n",
    "plt.xlim(0,1.0)\n",
    "plt.title(f\"{data_type} | {cond} {cond_name} | Train_size={size} | Length={LENGTH}\")\n",
    "\n",
    "plt.axvline(x=1/LENGTH, color='red', linewidth=0.5)\n",
    "#plt.plot([1/LENGTH]*len(local_heads), label='Uniform Weight')\n",
    "\n",
    "\n",
    "plt.show()\n",
    "print(f\"Model:{cur_model_path}\")\n",
    "#plt.savefig(f\"EOS_{cond}_{cond_name}_Train_size={size}_Length={LENGTH}.pdf\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(local_heads, alpha=0.5, label='Local (w/o self)', histtype='bar', color='red')\n",
    "plt.legend(loc='upper right')\n",
    "\n",
    "plt.ylabel('Number of Heads')\n",
    "plt.xlabel('Attention Weight To Local Environment (w\\o self)')\n",
    "plt.ylim(0,20)\n",
    "plt.xlim(0,1.0)\n",
    "plt.title(f\"{data_type} | {cond} {cond_name} | Train_size={size} | Length={LENGTH}\")\n",
    "\n",
    "plt.axvline(x=1/LENGTH, color='red', linewidth=0.5)\n",
    "\n",
    "\n",
    "plt.show()\n",
    "print(f\"Model:{cur_model_path}\")\n",
    "#plt.savefig(f\"Local_{cond}_{cond_name}_Train_size={size}_Length={LENGTH}.pdf\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(self_heads, alpha=0.5, label='Self', histtype='bar', color='green')\n",
    "plt.legend(loc='upper right')\n",
    "\n",
    "plt.ylabel('Number of Heads')\n",
    "plt.xlabel('Attention Weight To Self')\n",
    "plt.ylim(0,20)\n",
    "plt.xlim(0,1.0)\n",
    "plt.title(f\"{data_type} | {cond} {cond_name} | Train_size={size} | Length={LENGTH}\")\n",
    "\n",
    "plt.axvline(x=1/LENGTH, color='red', linewidth=0.5)\n",
    "\n",
    "\n",
    "plt.show()\n",
    "print(f\"Model:{cur_model_path}\")\n",
    "#plt.savefig(f\"Self_{cond}_{cond_name}_Train_size={size}_Length={LENGTH}.pdf\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(distance_weighted_median, alpha=0.5, label='Distance weighted median', histtype='bar', color='orange')\n",
    "plt.legend(loc='upper right')\n",
    "plt.ylabel('Number of Heads')\n",
    "plt.xlabel('Majority Distance')\n",
    "plt.ylim(0,20)\n",
    "plt.xlim(0,15)\n",
    "plt.title(f\"{data_type} | {cond} {cond_name} | Train_size={size} | Length={LENGTH}\")\n",
    "plt.show()\n",
    "print(f\"Model:{cur_model_path}\")\n",
    "#plt.savefig(f\"Distance_weighted_median_{cond}_{cond_name}_Train_size={size}_Length={LENGTH}.pdf\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(globality_scores, alpha=0.5, label='Globality Score', histtype='bar', color='black')\n",
    "plt.legend(loc='upper right')\n",
    "plt.ylabel('Number of Heads')\n",
    "plt.xlabel('Globality')\n",
    "plt.ylim(0,20)\n",
    "plt.xlim(0,0.5)\n",
    "plt.title(f\"{data_type} | {cond} {cond_name} | Train_size={size} | Length={LENGTH}\")\n",
    "plt.show()\n",
    "print(f\"Model:{cur_model_path}\")\n",
    "#plt.savefig(f\"Distance_weighted_median_{cond}_{cond_name}_Train_size={size}_Length={LENGTH}.pdf\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_focus_across_layers(self_heads, label='Self-focus', color='green')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_focus_across_layers(local_heads, label='Local-focus', color='red')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_focus_across_layers(distance_weighted_median, label='Median Distance', color='yellow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_focus_across_layers(globality_scores, label='Globality', color='grey')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_gm_scores = []\n",
    "# all_w_median_scores = []\n",
    "# for sample_num in range(samples_range[0], samples_range[1]):\n",
    "#     print(f\"sample_num: {sample_num}\", end=',')\n",
    "#     for i in range(NUM_LAYERS):\n",
    "#         for j in range(NUM_HEADS):\n",
    "#             gm_score, w_median = display_sample(i, j, sample_num, all_samples, cur_model_path, print_out=False)\n",
    "#             all_gm_scores.append((gm_score,sample_num,i,j))\n",
    "#             all_w_median_scores.append((w_median,sample_num,i,j))\n",
    "\n",
    "# from heapq import nlargest, nsmallest\n",
    "\n",
    "# def display_multipule_sample(samples_tuple_list):\n",
    "#     for sample_tuple in samples_tuple_list:\n",
    "#         display_sample(sample_tuple[2], sample_tuple[3], sample_tuple[1], all_samples, cur_model_path, print_out=True)\n",
    "#         print(\"=\"*120)\n",
    "\n",
    "# # k_top = 3\n",
    "# # display_list = [*nsmallest(k_top,all_gm_scores, key=lambda t: t[0]),\n",
    "# #                 *nsmallest(k_top,all_w_median_scores, key=lambda t: t[0]),\n",
    "# #                 *nlargest(k_top,all_gm_scores, key=lambda t: t[0]),\n",
    "# #                 *nlargest(k_top,all_w_median_scores, key=lambda t: t[0])] \n",
    "\n",
    "# display_list = [x for x in all_gm_scores if x[0]>=0.0 and x[0] <0.3]\n",
    "\n",
    "# print(f\"Model:{cur_model_path}\")\n",
    "# display_multipule_sample(display_list)\n",
    "\n",
    "# scores_of_interest = [x for x in all_gm_scores if x[0]>=0.3 and x[0] <0.5]\n",
    "# sns.heatmap(get_avg_attn_matrix_across_heads(scores_of_interest, cur_model_path, ignore_eos=True))\n",
    "\n",
    "# plt.hist([x[0] for x in all_w_median_scores], alpha=1.0, label='Weighted Median', histtype='bar')\n",
    "# plt.legend()\n",
    "\n",
    "# plt.hist([x[0] for x in all_gm_scores], alpha=0.5, label='Weighted Mean', histtype='bar', color='green')\n",
    "# plt.legend()\n",
    "\n",
    "# # - Get the median weighted distance (mwd) \n",
    "# # for the eos token attention for every head in every layer,\n",
    "# # for every sample, plot these values in a scatter plot,\n",
    "# # plotted against the layer number (so every point would be (mwd, layer number))\n",
    "\n",
    "# df = pd.DataFrame([(x[0],x[2]) for x in all_w_median_scores], columns=['WMD', 'Layers'])\n",
    "# sns.catplot(x=\"Layers\", y=\"WMD\", data=df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
